{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-01T12:24:22.531279Z",
     "start_time": "2025-07-01T12:20:23.438714Z"
    }
   },
   "cell_type": "code",
   "source": "!pip install matplotlib scikit-learn torch",
   "id": "49d9e4b66eb5897e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting matplotlib\r\n",
      "  Using cached matplotlib-3.10.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\r\n",
      "Collecting scikit-learn\r\n",
      "  Downloading scikit_learn-1.7.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (17 kB)\r\n",
      "Collecting torch\r\n",
      "  Downloading torch-2.7.1-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (29 kB)\r\n",
      "Collecting contourpy>=1.0.1 (from matplotlib)\r\n",
      "  Using cached contourpy-1.3.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.5 kB)\r\n",
      "Collecting cycler>=0.10 (from matplotlib)\r\n",
      "  Using cached cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\r\n",
      "Collecting fonttools>=4.22.0 (from matplotlib)\r\n",
      "  Downloading fonttools-4.58.4-cp312-cp312-manylinux1_x86_64.manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_5_x86_64.whl.metadata (106 kB)\r\n",
      "Collecting kiwisolver>=1.3.1 (from matplotlib)\r\n",
      "  Using cached kiwisolver-1.4.8-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.2 kB)\r\n",
      "Requirement already satisfied: numpy>=1.23 in ./venv/lib/python3.12/site-packages (from matplotlib) (2.3.1)\r\n",
      "Requirement already satisfied: packaging>=20.0 in ./venv/lib/python3.12/site-packages (from matplotlib) (25.0)\r\n",
      "Collecting pillow>=8 (from matplotlib)\r\n",
      "  Downloading pillow-11.3.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (9.0 kB)\r\n",
      "Collecting pyparsing>=2.3.1 (from matplotlib)\r\n",
      "  Using cached pyparsing-3.2.3-py3-none-any.whl.metadata (5.0 kB)\r\n",
      "Requirement already satisfied: python-dateutil>=2.7 in ./venv/lib/python3.12/site-packages (from matplotlib) (2.9.0.post0)\r\n",
      "Collecting scipy>=1.8.0 (from scikit-learn)\r\n",
      "  Downloading scipy-1.16.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (61 kB)\r\n",
      "Collecting joblib>=1.2.0 (from scikit-learn)\r\n",
      "  Downloading joblib-1.5.1-py3-none-any.whl.metadata (5.6 kB)\r\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn)\r\n",
      "  Downloading threadpoolctl-3.6.0-py3-none-any.whl.metadata (13 kB)\r\n",
      "Collecting filelock (from torch)\r\n",
      "  Downloading filelock-3.18.0-py3-none-any.whl.metadata (2.9 kB)\r\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in ./venv/lib/python3.12/site-packages (from torch) (4.14.0)\r\n",
      "Requirement already satisfied: setuptools in ./venv/lib/python3.12/site-packages (from torch) (80.9.0)\r\n",
      "Collecting sympy>=1.13.3 (from torch)\r\n",
      "  Downloading sympy-1.14.0-py3-none-any.whl.metadata (12 kB)\r\n",
      "Collecting networkx (from torch)\r\n",
      "  Downloading networkx-3.5-py3-none-any.whl.metadata (6.3 kB)\r\n",
      "Requirement already satisfied: jinja2 in ./venv/lib/python3.12/site-packages (from torch) (3.1.6)\r\n",
      "Collecting fsspec (from torch)\r\n",
      "  Downloading fsspec-2025.5.1-py3-none-any.whl.metadata (11 kB)\r\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.6.77 (from torch)\r\n",
      "  Downloading nvidia_cuda_nvrtc_cu12-12.6.77-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\r\n",
      "Collecting nvidia-cuda-runtime-cu12==12.6.77 (from torch)\r\n",
      "  Downloading nvidia_cuda_runtime_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\r\n",
      "Collecting nvidia-cuda-cupti-cu12==12.6.80 (from torch)\r\n",
      "  Downloading nvidia_cuda_cupti_cu12-12.6.80-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\r\n",
      "Collecting nvidia-cudnn-cu12==9.5.1.17 (from torch)\r\n",
      "  Downloading nvidia_cudnn_cu12-9.5.1.17-py3-none-manylinux_2_28_x86_64.whl.metadata (1.6 kB)\r\n",
      "Collecting nvidia-cublas-cu12==12.6.4.1 (from torch)\r\n",
      "  Downloading nvidia_cublas_cu12-12.6.4.1-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\r\n",
      "Collecting nvidia-cufft-cu12==11.3.0.4 (from torch)\r\n",
      "  Downloading nvidia_cufft_cu12-11.3.0.4-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\r\n",
      "Collecting nvidia-curand-cu12==10.3.7.77 (from torch)\r\n",
      "  Downloading nvidia_curand_cu12-10.3.7.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\r\n",
      "Collecting nvidia-cusolver-cu12==11.7.1.2 (from torch)\r\n",
      "  Downloading nvidia_cusolver_cu12-11.7.1.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\r\n",
      "Collecting nvidia-cusparse-cu12==12.5.4.2 (from torch)\r\n",
      "  Downloading nvidia_cusparse_cu12-12.5.4.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\r\n",
      "Collecting nvidia-cusparselt-cu12==0.6.3 (from torch)\r\n",
      "  Downloading nvidia_cusparselt_cu12-0.6.3-py3-none-manylinux2014_x86_64.whl.metadata (6.8 kB)\r\n",
      "Collecting nvidia-nccl-cu12==2.26.2 (from torch)\r\n",
      "  Downloading nvidia_nccl_cu12-2.26.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.0 kB)\r\n",
      "Collecting nvidia-nvtx-cu12==12.6.77 (from torch)\r\n",
      "  Downloading nvidia_nvtx_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\r\n",
      "Collecting nvidia-nvjitlink-cu12==12.6.85 (from torch)\r\n",
      "  Downloading nvidia_nvjitlink_cu12-12.6.85-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.5 kB)\r\n",
      "Collecting nvidia-cufile-cu12==1.11.1.6 (from torch)\r\n",
      "  Downloading nvidia_cufile_cu12-1.11.1.6-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\r\n",
      "Collecting triton==3.3.1 (from torch)\r\n",
      "  Downloading triton-3.3.1-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (1.5 kB)\r\n",
      "Requirement already satisfied: six>=1.5 in ./venv/lib/python3.12/site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\r\n",
      "Collecting mpmath<1.4,>=1.1.0 (from sympy>=1.13.3->torch)\r\n",
      "  Downloading mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./venv/lib/python3.12/site-packages (from jinja2->torch) (3.0.2)\r\n",
      "Using cached matplotlib-3.10.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.6 MB)\r\n",
      "Downloading scikit_learn-1.7.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.5 MB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m12.5/12.5 MB\u001B[0m \u001B[31m15.9 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m0:01\u001B[0m\r\n",
      "\u001B[?25hDownloading torch-2.7.1-cp312-cp312-manylinux_2_28_x86_64.whl (821.0 MB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m821.0/821.0 MB\u001B[0m \u001B[31m23.2 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:01\u001B[0m\r\n",
      "\u001B[?25hDownloading nvidia_cublas_cu12-12.6.4.1-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (393.1 MB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m393.1/393.1 MB\u001B[0m \u001B[31m28.2 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:01\u001B[0m\r\n",
      "\u001B[?25hDownloading nvidia_cuda_cupti_cu12-12.6.80-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (8.9 MB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m8.9/8.9 MB\u001B[0m \u001B[31m32.0 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0ma \u001B[36m0:00:01\u001B[0m\r\n",
      "\u001B[?25hDownloading nvidia_cuda_nvrtc_cu12-12.6.77-py3-none-manylinux2014_x86_64.whl (23.7 MB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m23.7/23.7 MB\u001B[0m \u001B[31m30.8 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0ma \u001B[36m0:00:01\u001B[0m\r\n",
      "\u001B[?25hDownloading nvidia_cuda_runtime_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (897 kB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m897.7/897.7 kB\u001B[0m \u001B[31m19.8 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25hDownloading nvidia_cudnn_cu12-9.5.1.17-py3-none-manylinux_2_28_x86_64.whl (571.0 MB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m571.0/571.0 MB\u001B[0m \u001B[31m24.4 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:01\u001B[0m\r\n",
      "\u001B[?25hDownloading nvidia_cufft_cu12-11.3.0.4-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (200.2 MB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m200.2/200.2 MB\u001B[0m \u001B[31m27.5 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:01\u001B[0m\r\n",
      "\u001B[?25hDownloading nvidia_cufile_cu12-1.11.1.6-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (1.1 MB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m1.1/1.1 MB\u001B[0m \u001B[31m26.3 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25hDownloading nvidia_curand_cu12-10.3.7.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (56.3 MB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m56.3/56.3 MB\u001B[0m \u001B[31m28.5 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:01\u001B[0m\r\n",
      "\u001B[?25hDownloading nvidia_cusolver_cu12-11.7.1.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (158.2 MB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m158.2/158.2 MB\u001B[0m \u001B[31m29.6 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:01\u001B[0m\r\n",
      "\u001B[?25hDownloading nvidia_cusparse_cu12-12.5.4.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (216.6 MB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m216.6/216.6 MB\u001B[0m \u001B[31m28.6 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:01\u001B[0m\r\n",
      "\u001B[?25hDownloading nvidia_cusparselt_cu12-0.6.3-py3-none-manylinux2014_x86_64.whl (156.8 MB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m156.8/156.8 MB\u001B[0m \u001B[31m28.6 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:01\u001B[0m\r\n",
      "\u001B[?25hDownloading nvidia_nccl_cu12-2.26.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (201.3 MB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m201.3/201.3 MB\u001B[0m \u001B[31m29.4 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:01\u001B[0m\r\n",
      "\u001B[?25hDownloading nvidia_nvjitlink_cu12-12.6.85-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (19.7 MB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m19.7/19.7 MB\u001B[0m \u001B[31m26.5 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:01\u001B[0m\r\n",
      "\u001B[?25hDownloading nvidia_nvtx_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (89 kB)\r\n",
      "Downloading triton-3.3.1-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (155.7 MB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m155.7/155.7 MB\u001B[0m \u001B[31m30.2 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:01\u001B[0m\r\n",
      "\u001B[?25hUsing cached contourpy-1.3.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (323 kB)\r\n",
      "Using cached cycler-0.12.1-py3-none-any.whl (8.3 kB)\r\n",
      "Downloading fonttools-4.58.4-cp312-cp312-manylinux1_x86_64.manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_5_x86_64.whl (4.9 MB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m4.9/4.9 MB\u001B[0m \u001B[31m26.9 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25hDownloading joblib-1.5.1-py3-none-any.whl (307 kB)\r\n",
      "Using cached kiwisolver-1.4.8-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.5 MB)\r\n",
      "Downloading pillow-11.3.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (6.6 MB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m6.6/6.6 MB\u001B[0m \u001B[31m25.5 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m\r\n",
      "\u001B[?25hUsing cached pyparsing-3.2.3-py3-none-any.whl (111 kB)\r\n",
      "Downloading scipy-1.16.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (35.1 MB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m35.1/35.1 MB\u001B[0m \u001B[31m28.5 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:01\u001B[0m\r\n",
      "\u001B[?25hDownloading sympy-1.14.0-py3-none-any.whl (6.3 MB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m6.3/6.3 MB\u001B[0m \u001B[31m29.2 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m\r\n",
      "\u001B[?25hDownloading threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\r\n",
      "Downloading filelock-3.18.0-py3-none-any.whl (16 kB)\r\n",
      "Downloading fsspec-2025.5.1-py3-none-any.whl (199 kB)\r\n",
      "Downloading networkx-3.5-py3-none-any.whl (2.0 MB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m2.0/2.0 MB\u001B[0m \u001B[31m27.4 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25hDownloading mpmath-1.3.0-py3-none-any.whl (536 kB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m536.2/536.2 kB\u001B[0m \u001B[31m14.9 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25hInstalling collected packages: nvidia-cusparselt-cu12, mpmath, triton, threadpoolctl, sympy, scipy, pyparsing, pillow, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufile-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, networkx, kiwisolver, joblib, fsspec, fonttools, filelock, cycler, contourpy, scikit-learn, nvidia-cusparse-cu12, nvidia-cufft-cu12, nvidia-cudnn-cu12, matplotlib, nvidia-cusolver-cu12, torch\r\n",
      "Successfully installed contourpy-1.3.2 cycler-0.12.1 filelock-3.18.0 fonttools-4.58.4 fsspec-2025.5.1 joblib-1.5.1 kiwisolver-1.4.8 matplotlib-3.10.3 mpmath-1.3.0 networkx-3.5 nvidia-cublas-cu12-12.6.4.1 nvidia-cuda-cupti-cu12-12.6.80 nvidia-cuda-nvrtc-cu12-12.6.77 nvidia-cuda-runtime-cu12-12.6.77 nvidia-cudnn-cu12-9.5.1.17 nvidia-cufft-cu12-11.3.0.4 nvidia-cufile-cu12-1.11.1.6 nvidia-curand-cu12-10.3.7.77 nvidia-cusolver-cu12-11.7.1.2 nvidia-cusparse-cu12-12.5.4.2 nvidia-cusparselt-cu12-0.6.3 nvidia-nccl-cu12-2.26.2 nvidia-nvjitlink-cu12-12.6.85 nvidia-nvtx-cu12-12.6.77 pillow-11.3.0 pyparsing-3.2.3 scikit-learn-1.7.0 scipy-1.16.0 sympy-1.14.0 threadpoolctl-3.6.0 torch-2.7.1 triton-3.3.1\r\n",
      "\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip is available: \u001B[0m\u001B[31;49m25.0.1\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m25.1.1\u001B[0m\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49mpip install --upgrade pip\u001B[0m\r\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-07-01T12:24:37.084762Z",
     "start_time": "2025-07-01T12:24:27.852662Z"
    }
   },
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-01T12:24:37.170561Z",
     "start_time": "2025-07-01T12:24:37.159367Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def map_label(lbl):\n",
    "    mapping = {\n",
    "        'null': 0,\n",
    "        'jogging': 1,\n",
    "        'jogging (rotating arms)': 2,\n",
    "        'jogging (skipping)': 3,\n",
    "        'jogging (sidesteps)': 4,\n",
    "        'jogging (butt-kicks)': 5,\n",
    "        'stretching (triceps)': 6,\n",
    "        'stretching (lunging)': 7,\n",
    "        'stretching (shoulders)': 8,\n",
    "        'stretching (hamstrings)': 9,\n",
    "        'stretching (lumbar rotation)': 10,\n",
    "        'push-ups': 11,\n",
    "        'push-ups (complex)': 12,\n",
    "        'sit-ups': 13,\n",
    "        'sit-ups (complex)': 14,\n",
    "        'burpees': 15,\n",
    "        'lunges': 16,\n",
    "        'lunges (complex)': 17,\n",
    "        'bench-dips': 18\n",
    "    }\n",
    "    return mapping.get(lbl, np.nan)\n",
    "label_map = {\n",
    "    'null': 0,'jogging': 1,'jogging (rotating arms)': 2,'jogging (skipping)': 3,'jogging (sidesteps)': 4,'jogging (butt-kicks)': 5,\n",
    "    'stretching (triceps)': 6,'stretching (lunging)': 7,'stretching (shoulders)': 8,'stretching (hamstrings)': 9,'stretching (lumbar rotation)': 10,\n",
    "    'push-ups': 11,'push-ups (complex)': 12,'sit-ups': 13,'sit-ups (complex)': 14,'burpees': 15,'lunges': 16,'lunges (complex)': 17,'bench-dips': 18\n",
    "}"
   ],
   "id": "82fda4b5397b7b02",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-01T12:24:41.327826Z",
     "start_time": "2025-07-01T12:24:37.238350Z"
    }
   },
   "cell_type": "code",
   "source": "!pip install scikit-learn torch tqdm",
   "id": "f5e1ed428a3c86fd",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in ./venv/lib/python3.12/site-packages (1.7.0)\r\n",
      "Requirement already satisfied: torch in ./venv/lib/python3.12/site-packages (2.7.1)\r\n",
      "Requirement already satisfied: tqdm in ./venv/lib/python3.12/site-packages (4.67.1)\r\n",
      "Requirement already satisfied: numpy>=1.22.0 in ./venv/lib/python3.12/site-packages (from scikit-learn) (2.3.1)\r\n",
      "Requirement already satisfied: scipy>=1.8.0 in ./venv/lib/python3.12/site-packages (from scikit-learn) (1.16.0)\r\n",
      "Requirement already satisfied: joblib>=1.2.0 in ./venv/lib/python3.12/site-packages (from scikit-learn) (1.5.1)\r\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in ./venv/lib/python3.12/site-packages (from scikit-learn) (3.6.0)\r\n",
      "Requirement already satisfied: filelock in ./venv/lib/python3.12/site-packages (from torch) (3.18.0)\r\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in ./venv/lib/python3.12/site-packages (from torch) (4.14.0)\r\n",
      "Requirement already satisfied: setuptools in ./venv/lib/python3.12/site-packages (from torch) (80.9.0)\r\n",
      "Requirement already satisfied: sympy>=1.13.3 in ./venv/lib/python3.12/site-packages (from torch) (1.14.0)\r\n",
      "Requirement already satisfied: networkx in ./venv/lib/python3.12/site-packages (from torch) (3.5)\r\n",
      "Requirement already satisfied: jinja2 in ./venv/lib/python3.12/site-packages (from torch) (3.1.6)\r\n",
      "Requirement already satisfied: fsspec in ./venv/lib/python3.12/site-packages (from torch) (2025.5.1)\r\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in ./venv/lib/python3.12/site-packages (from torch) (12.6.77)\r\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in ./venv/lib/python3.12/site-packages (from torch) (12.6.77)\r\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in ./venv/lib/python3.12/site-packages (from torch) (12.6.80)\r\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.5.1.17 in ./venv/lib/python3.12/site-packages (from torch) (9.5.1.17)\r\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in ./venv/lib/python3.12/site-packages (from torch) (12.6.4.1)\r\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in ./venv/lib/python3.12/site-packages (from torch) (11.3.0.4)\r\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in ./venv/lib/python3.12/site-packages (from torch) (10.3.7.77)\r\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in ./venv/lib/python3.12/site-packages (from torch) (11.7.1.2)\r\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in ./venv/lib/python3.12/site-packages (from torch) (12.5.4.2)\r\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.3 in ./venv/lib/python3.12/site-packages (from torch) (0.6.3)\r\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.26.2 in ./venv/lib/python3.12/site-packages (from torch) (2.26.2)\r\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in ./venv/lib/python3.12/site-packages (from torch) (12.6.77)\r\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in ./venv/lib/python3.12/site-packages (from torch) (12.6.85)\r\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in ./venv/lib/python3.12/site-packages (from torch) (1.11.1.6)\r\n",
      "Requirement already satisfied: triton==3.3.1 in ./venv/lib/python3.12/site-packages (from torch) (3.3.1)\r\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in ./venv/lib/python3.12/site-packages (from sympy>=1.13.3->torch) (1.3.0)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./venv/lib/python3.12/site-packages (from jinja2->torch) (3.0.2)\r\n",
      "\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip is available: \u001B[0m\u001B[31;49m25.0.1\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m25.1.1\u001B[0m\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49mpip install --upgrade pip\u001B[0m\r\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-01T12:24:41.365168Z",
     "start_time": "2025-07-01T12:24:41.355803Z"
    }
   },
   "cell_type": "code",
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")"
   ],
   "id": "e7d356c362698446",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-01T12:25:07.522471Z",
     "start_time": "2025-07-01T12:25:07.518023Z"
    }
   },
   "cell_type": "code",
   "source": [
    "data_dir = Path('data')\n",
    "train_dir = data_dir / 'train'\n",
    "meta_file = data_dir / 'meta_data.txt'\n",
    "test_file = data_dir/'test.csv'"
   ],
   "id": "16c505d6405138c9",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-01T12:25:26.645466Z",
     "start_time": "2025-07-01T12:25:11.951044Z"
    }
   },
   "cell_type": "code",
   "source": [
    "sbj_files = sorted(train_dir.glob('sbj_*.csv'))\n",
    "print(len(sbj_files))\n",
    "dfs = []\n",
    "for f in sbj_files:\n",
    "    df = pd.read_csv(f,low_memory=False)\n",
    "    df['subject'] = df['sbj_id'].astype(str)\n",
    "    dfs.append(df)\n",
    "\n",
    "raw_df = pd.concat(dfs, ignore_index=True)\n",
    "print(raw_df.columns.tolist())\n",
    "display(raw_df.head())\n"
   ],
   "id": "3aeff3b10196f44f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24\n",
      "['sbj_id', 'right_arm_acc_x', 'right_arm_acc_y', 'right_arm_acc_z', 'right_leg_acc_x', 'right_leg_acc_y', 'right_leg_acc_z', 'left_leg_acc_x', 'left_leg_acc_y', 'left_leg_acc_z', 'left_arm_acc_x', 'left_arm_acc_y', 'left_arm_acc_z', 'label', 'subject']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "   sbj_id  right_arm_acc_x  right_arm_acc_y  right_arm_acc_z  right_leg_acc_x  \\\n",
       "0       0         1.111720         0.064550         0.042595         0.982813   \n",
       "1       0         1.177174         0.231861        -0.003207         0.988545   \n",
       "2       0         1.124248         0.264661        -0.027485         0.982286   \n",
       "3       0         1.032746         0.236885        -0.066591         0.981618   \n",
       "4       0         0.974202         0.262050        -0.116387         0.988576   \n",
       "\n",
       "   right_leg_acc_y  right_leg_acc_z  left_leg_acc_x  left_leg_acc_y  \\\n",
       "0         0.113823         0.152618        0.978287       -0.111472   \n",
       "1         0.143807         0.144880        0.979794       -0.100042   \n",
       "2         0.155609         0.135133        0.982915       -0.095342   \n",
       "3         0.141745         0.134765        0.981991       -0.126157   \n",
       "4         0.120453         0.143329        0.977757       -0.124765   \n",
       "\n",
       "   left_leg_acc_z  left_arm_acc_x  left_arm_acc_y  left_arm_acc_z label  \\\n",
       "0        0.103445       -0.956057       -0.407509       -0.090828   NaN   \n",
       "1        0.086984       -1.122597       -0.232949       -0.106347   NaN   \n",
       "2        0.083391       -1.167835       -0.088288       -0.131609   NaN   \n",
       "3        0.088388       -1.143375        0.015024       -0.145414   NaN   \n",
       "4        0.113024       -1.063969        0.080970       -0.140224   NaN   \n",
       "\n",
       "  subject  \n",
       "0       0  \n",
       "1       0  \n",
       "2       0  \n",
       "3       0  \n",
       "4       0  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sbj_id</th>\n",
       "      <th>right_arm_acc_x</th>\n",
       "      <th>right_arm_acc_y</th>\n",
       "      <th>right_arm_acc_z</th>\n",
       "      <th>right_leg_acc_x</th>\n",
       "      <th>right_leg_acc_y</th>\n",
       "      <th>right_leg_acc_z</th>\n",
       "      <th>left_leg_acc_x</th>\n",
       "      <th>left_leg_acc_y</th>\n",
       "      <th>left_leg_acc_z</th>\n",
       "      <th>left_arm_acc_x</th>\n",
       "      <th>left_arm_acc_y</th>\n",
       "      <th>left_arm_acc_z</th>\n",
       "      <th>label</th>\n",
       "      <th>subject</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1.111720</td>\n",
       "      <td>0.064550</td>\n",
       "      <td>0.042595</td>\n",
       "      <td>0.982813</td>\n",
       "      <td>0.113823</td>\n",
       "      <td>0.152618</td>\n",
       "      <td>0.978287</td>\n",
       "      <td>-0.111472</td>\n",
       "      <td>0.103445</td>\n",
       "      <td>-0.956057</td>\n",
       "      <td>-0.407509</td>\n",
       "      <td>-0.090828</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1.177174</td>\n",
       "      <td>0.231861</td>\n",
       "      <td>-0.003207</td>\n",
       "      <td>0.988545</td>\n",
       "      <td>0.143807</td>\n",
       "      <td>0.144880</td>\n",
       "      <td>0.979794</td>\n",
       "      <td>-0.100042</td>\n",
       "      <td>0.086984</td>\n",
       "      <td>-1.122597</td>\n",
       "      <td>-0.232949</td>\n",
       "      <td>-0.106347</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1.124248</td>\n",
       "      <td>0.264661</td>\n",
       "      <td>-0.027485</td>\n",
       "      <td>0.982286</td>\n",
       "      <td>0.155609</td>\n",
       "      <td>0.135133</td>\n",
       "      <td>0.982915</td>\n",
       "      <td>-0.095342</td>\n",
       "      <td>0.083391</td>\n",
       "      <td>-1.167835</td>\n",
       "      <td>-0.088288</td>\n",
       "      <td>-0.131609</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1.032746</td>\n",
       "      <td>0.236885</td>\n",
       "      <td>-0.066591</td>\n",
       "      <td>0.981618</td>\n",
       "      <td>0.141745</td>\n",
       "      <td>0.134765</td>\n",
       "      <td>0.981991</td>\n",
       "      <td>-0.126157</td>\n",
       "      <td>0.088388</td>\n",
       "      <td>-1.143375</td>\n",
       "      <td>0.015024</td>\n",
       "      <td>-0.145414</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.974202</td>\n",
       "      <td>0.262050</td>\n",
       "      <td>-0.116387</td>\n",
       "      <td>0.988576</td>\n",
       "      <td>0.120453</td>\n",
       "      <td>0.143329</td>\n",
       "      <td>0.977757</td>\n",
       "      <td>-0.124765</td>\n",
       "      <td>0.113024</td>\n",
       "      <td>-1.063969</td>\n",
       "      <td>0.080970</td>\n",
       "      <td>-0.140224</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-01T12:25:32.985852Z",
     "start_time": "2025-07-01T12:25:26.751973Z"
    }
   },
   "cell_type": "code",
   "source": [
    "raw_df['label_code'] = raw_df['label'].apply(map_label)\n",
    "raw_df = raw_df.dropna(subset=['label_code']).reset_index(drop=True)\n",
    "raw_df['label_code'] = raw_df['label_code'].astype(int)\n",
    "\n",
    "sensor_cols = [c for c in raw_df.columns if c not in ['sbj_id', 'subject', 'label', 'label_code']]\n",
    "raw_df = raw_df.dropna(subset=sensor_cols).reset_index(drop=True)\n",
    "scaler = StandardScaler()\n",
    "raw_df[sensor_cols] = scaler.fit_transform(raw_df[sensor_cols])\n",
    "\n",
    "raw_df"
   ],
   "id": "ac90c21afaef0159",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "         sbj_id  right_arm_acc_x  right_arm_acc_y  right_arm_acc_z  \\\n",
       "0             0         0.338590         0.120549         0.717712   \n",
       "1             0         0.267886         0.133180         0.748476   \n",
       "2             0         0.271598         0.158237         0.777007   \n",
       "3             0         0.346738         0.196146         0.795026   \n",
       "4             0         0.423578         0.231633         0.814875   \n",
       "...         ...              ...              ...              ...   \n",
       "2054759       9         0.660601        -0.674779         0.036996   \n",
       "2054760       9         0.671317        -0.672684         0.074857   \n",
       "2054761       9         0.674111        -0.697452         0.119595   \n",
       "2054762       9         0.660443        -0.734104         0.114785   \n",
       "2054763       9         0.650215        -0.757013         0.091513   \n",
       "\n",
       "         right_leg_acc_x  right_leg_acc_y  right_leg_acc_z  left_leg_acc_x  \\\n",
       "0               0.294029         0.120450         0.139363        0.486923   \n",
       "1               0.297809         0.085421         0.120335        0.541998   \n",
       "2               0.295387         0.078235         0.098782        0.701439   \n",
       "3               0.296009         0.080996         0.106860        1.079330   \n",
       "4               0.303610         0.072211         0.168760        0.928822   \n",
       "...                  ...              ...              ...             ...   \n",
       "2054759        -0.878534         1.191544         0.817278       -0.760971   \n",
       "2054760        -0.849709         1.158368         0.741078       -0.755161   \n",
       "2054761        -0.807822         1.139071         0.600962       -0.761807   \n",
       "2054762        -0.767200         1.132643         0.498166       -0.780179   \n",
       "2054763        -0.703132         1.130372         0.437217       -0.806730   \n",
       "\n",
       "         left_leg_acc_y  left_leg_acc_z  left_arm_acc_x  left_arm_acc_y  \\\n",
       "0             -0.235985       -0.023205       -0.515422        0.331682   \n",
       "1             -0.236344        0.110817       -0.478973        0.336796   \n",
       "2             -0.146195        0.360308       -0.411302        0.327018   \n",
       "3             -0.066705        0.793745       -0.349172        0.311192   \n",
       "4             -0.216602        0.634914       -0.295446        0.247657   \n",
       "...                 ...             ...             ...             ...   \n",
       "2054759        0.802049        1.221196       -0.660437       -0.716009   \n",
       "2054760        0.787947        1.301947       -0.663010       -0.723955   \n",
       "2054761        0.774746        1.326825       -0.662831       -0.700415   \n",
       "2054762        0.776143        1.301909       -0.663853       -0.702628   \n",
       "2054763        0.784055        1.261521       -0.663683       -0.719146   \n",
       "\n",
       "         left_arm_acc_z       label subject  label_code  \n",
       "0              0.323862     jogging       0           1  \n",
       "1              0.330691     jogging       0           1  \n",
       "2              0.366185     jogging       0           1  \n",
       "3              0.397661     jogging       0           1  \n",
       "4              0.381219     jogging       0           1  \n",
       "...                 ...         ...     ...         ...  \n",
       "2054759        0.319617  bench-dips       9          18  \n",
       "2054760        0.356210  bench-dips       9          18  \n",
       "2054761        0.299180  bench-dips       9          18  \n",
       "2054762        0.306702  bench-dips       9          18  \n",
       "2054763        0.334693  bench-dips       9          18  \n",
       "\n",
       "[2054764 rows x 16 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sbj_id</th>\n",
       "      <th>right_arm_acc_x</th>\n",
       "      <th>right_arm_acc_y</th>\n",
       "      <th>right_arm_acc_z</th>\n",
       "      <th>right_leg_acc_x</th>\n",
       "      <th>right_leg_acc_y</th>\n",
       "      <th>right_leg_acc_z</th>\n",
       "      <th>left_leg_acc_x</th>\n",
       "      <th>left_leg_acc_y</th>\n",
       "      <th>left_leg_acc_z</th>\n",
       "      <th>left_arm_acc_x</th>\n",
       "      <th>left_arm_acc_y</th>\n",
       "      <th>left_arm_acc_z</th>\n",
       "      <th>label</th>\n",
       "      <th>subject</th>\n",
       "      <th>label_code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.338590</td>\n",
       "      <td>0.120549</td>\n",
       "      <td>0.717712</td>\n",
       "      <td>0.294029</td>\n",
       "      <td>0.120450</td>\n",
       "      <td>0.139363</td>\n",
       "      <td>0.486923</td>\n",
       "      <td>-0.235985</td>\n",
       "      <td>-0.023205</td>\n",
       "      <td>-0.515422</td>\n",
       "      <td>0.331682</td>\n",
       "      <td>0.323862</td>\n",
       "      <td>jogging</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.267886</td>\n",
       "      <td>0.133180</td>\n",
       "      <td>0.748476</td>\n",
       "      <td>0.297809</td>\n",
       "      <td>0.085421</td>\n",
       "      <td>0.120335</td>\n",
       "      <td>0.541998</td>\n",
       "      <td>-0.236344</td>\n",
       "      <td>0.110817</td>\n",
       "      <td>-0.478973</td>\n",
       "      <td>0.336796</td>\n",
       "      <td>0.330691</td>\n",
       "      <td>jogging</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.271598</td>\n",
       "      <td>0.158237</td>\n",
       "      <td>0.777007</td>\n",
       "      <td>0.295387</td>\n",
       "      <td>0.078235</td>\n",
       "      <td>0.098782</td>\n",
       "      <td>0.701439</td>\n",
       "      <td>-0.146195</td>\n",
       "      <td>0.360308</td>\n",
       "      <td>-0.411302</td>\n",
       "      <td>0.327018</td>\n",
       "      <td>0.366185</td>\n",
       "      <td>jogging</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0.346738</td>\n",
       "      <td>0.196146</td>\n",
       "      <td>0.795026</td>\n",
       "      <td>0.296009</td>\n",
       "      <td>0.080996</td>\n",
       "      <td>0.106860</td>\n",
       "      <td>1.079330</td>\n",
       "      <td>-0.066705</td>\n",
       "      <td>0.793745</td>\n",
       "      <td>-0.349172</td>\n",
       "      <td>0.311192</td>\n",
       "      <td>0.397661</td>\n",
       "      <td>jogging</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.423578</td>\n",
       "      <td>0.231633</td>\n",
       "      <td>0.814875</td>\n",
       "      <td>0.303610</td>\n",
       "      <td>0.072211</td>\n",
       "      <td>0.168760</td>\n",
       "      <td>0.928822</td>\n",
       "      <td>-0.216602</td>\n",
       "      <td>0.634914</td>\n",
       "      <td>-0.295446</td>\n",
       "      <td>0.247657</td>\n",
       "      <td>0.381219</td>\n",
       "      <td>jogging</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2054759</th>\n",
       "      <td>9</td>\n",
       "      <td>0.660601</td>\n",
       "      <td>-0.674779</td>\n",
       "      <td>0.036996</td>\n",
       "      <td>-0.878534</td>\n",
       "      <td>1.191544</td>\n",
       "      <td>0.817278</td>\n",
       "      <td>-0.760971</td>\n",
       "      <td>0.802049</td>\n",
       "      <td>1.221196</td>\n",
       "      <td>-0.660437</td>\n",
       "      <td>-0.716009</td>\n",
       "      <td>0.319617</td>\n",
       "      <td>bench-dips</td>\n",
       "      <td>9</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2054760</th>\n",
       "      <td>9</td>\n",
       "      <td>0.671317</td>\n",
       "      <td>-0.672684</td>\n",
       "      <td>0.074857</td>\n",
       "      <td>-0.849709</td>\n",
       "      <td>1.158368</td>\n",
       "      <td>0.741078</td>\n",
       "      <td>-0.755161</td>\n",
       "      <td>0.787947</td>\n",
       "      <td>1.301947</td>\n",
       "      <td>-0.663010</td>\n",
       "      <td>-0.723955</td>\n",
       "      <td>0.356210</td>\n",
       "      <td>bench-dips</td>\n",
       "      <td>9</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2054761</th>\n",
       "      <td>9</td>\n",
       "      <td>0.674111</td>\n",
       "      <td>-0.697452</td>\n",
       "      <td>0.119595</td>\n",
       "      <td>-0.807822</td>\n",
       "      <td>1.139071</td>\n",
       "      <td>0.600962</td>\n",
       "      <td>-0.761807</td>\n",
       "      <td>0.774746</td>\n",
       "      <td>1.326825</td>\n",
       "      <td>-0.662831</td>\n",
       "      <td>-0.700415</td>\n",
       "      <td>0.299180</td>\n",
       "      <td>bench-dips</td>\n",
       "      <td>9</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2054762</th>\n",
       "      <td>9</td>\n",
       "      <td>0.660443</td>\n",
       "      <td>-0.734104</td>\n",
       "      <td>0.114785</td>\n",
       "      <td>-0.767200</td>\n",
       "      <td>1.132643</td>\n",
       "      <td>0.498166</td>\n",
       "      <td>-0.780179</td>\n",
       "      <td>0.776143</td>\n",
       "      <td>1.301909</td>\n",
       "      <td>-0.663853</td>\n",
       "      <td>-0.702628</td>\n",
       "      <td>0.306702</td>\n",
       "      <td>bench-dips</td>\n",
       "      <td>9</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2054763</th>\n",
       "      <td>9</td>\n",
       "      <td>0.650215</td>\n",
       "      <td>-0.757013</td>\n",
       "      <td>0.091513</td>\n",
       "      <td>-0.703132</td>\n",
       "      <td>1.130372</td>\n",
       "      <td>0.437217</td>\n",
       "      <td>-0.806730</td>\n",
       "      <td>0.784055</td>\n",
       "      <td>1.261521</td>\n",
       "      <td>-0.663683</td>\n",
       "      <td>-0.719146</td>\n",
       "      <td>0.334693</td>\n",
       "      <td>bench-dips</td>\n",
       "      <td>9</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2054764 rows × 16 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-01T12:25:33.089765Z",
     "start_time": "2025-07-01T12:25:33.084482Z"
    }
   },
   "cell_type": "code",
   "source": [
    "WINDOW_SIZE = 128\n",
    "STEP_SIZE = 64\n",
    "\n",
    "def create_sequences(df, sensor_cols, target_col, window, step):\n",
    "    X, y = [], []\n",
    "    data = df[sensor_cols].values\n",
    "    labels = df[target_col].values\n",
    "    for start in range(0, len(df) - window + 1, step):\n",
    "        end = start + window\n",
    "        seq = data[start:end]\n",
    "        lab = np.bincount(labels[start:end]).argmax()\n",
    "        X.append(seq)\n",
    "        y.append(lab)\n",
    "    return np.array(X), np.array(y)"
   ],
   "id": "3c0281dd211fe4b8",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-01T12:25:38.003300Z",
     "start_time": "2025-07-01T12:25:33.179295Z"
    }
   },
   "cell_type": "code",
   "source": [
    "all_X, all_y = [], []\n",
    "for subj in raw_df['subject'].unique():\n",
    "    df_sub = raw_df[raw_df['subject'] == subj].reset_index(drop=True)\n",
    "    X_sub, y_sub = create_sequences(df_sub, sensor_cols, 'label_code', WINDOW_SIZE, STEP_SIZE)\n",
    "    all_X.append(X_sub)\n",
    "    all_y.append(y_sub)\n",
    "X = np.vstack(all_X)\n",
    "y = np.hstack(all_y)\n",
    "print(f\"X shape: {X.shape}, y shape: {y.shape}\")\n",
    "\n",
    "# Train/Test Split\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
    "\n",
    "torch.manual_seed(42)"
   ],
   "id": "d77a9b7072418d54",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (32073, 128, 12), y shape: (32073,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7afd6c087bb0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "60ce60a44c3f93f8"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-01T12:36:02.780631Z",
     "start_time": "2025-07-01T12:36:02.220177Z"
    }
   },
   "cell_type": "code",
   "source": [
    "right_arm_df = raw_df[[\"right_arm_acc_x\", \"right_arm_acc_y\", \"right_arm_acc_z\", \"subject\", \"label_code\"]]\n",
    "left_arm_df = raw_df[[\"left_arm_acc_x\", \"left_arm_acc_y\", \"left_arm_acc_z\", \"subject\", \"label_code\"]]\n",
    "right_leg_df = raw_df[[\"right_leg_acc_x\", \"right_leg_acc_y\", \"right_leg_acc_z\", \"subject\", \"label_code\"]]\n",
    "left_leg_df = raw_df[[\"left_leg_acc_x\", \"left_leg_acc_y\", \"left_leg_acc_z\", \"subject\", \"label_code\"]]\n"
   ],
   "id": "cb00afab9d56f041",
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "f19fd24eded89ae"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-01T12:25:40.587464Z",
     "start_time": "2025-07-01T12:25:40.495889Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class SensorDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = torch.tensor(X, dtype=torch.float32)\n",
    "        self.y = torch.tensor(y, dtype=torch.long)\n",
    "    def __len__(self): return len(self.X)\n",
    "    def __getitem__(self, idx): return self.X[idx], self.y[idx]\n",
    "\n",
    "batch_size = 64\n",
    "train_loader = DataLoader(SensorDataset(X_train, y_train), batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "val_loader = DataLoader(SensorDataset(X_val, y_val), batch_size=batch_size)\n",
    "\n",
    "d = len(sensor_cols)\n",
    "num_classes = 19#len(set(y))"
   ],
   "id": "ead9bc36ccf6d407",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-19T20:47:50.386527Z",
     "start_time": "2025-06-19T20:47:50.303260Z"
    }
   },
   "cell_type": "code",
   "source": "set(y)",
   "id": "fae24bbf27ba8627",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{np.int64(1),\n",
       " np.int64(2),\n",
       " np.int64(3),\n",
       " np.int64(4),\n",
       " np.int64(5),\n",
       " np.int64(6),\n",
       " np.int64(7),\n",
       " np.int64(8),\n",
       " np.int64(9),\n",
       " np.int64(10),\n",
       " np.int64(11),\n",
       " np.int64(12),\n",
       " np.int64(13),\n",
       " np.int64(14),\n",
       " np.int64(15),\n",
       " np.int64(16),\n",
       " np.int64(17),\n",
       " np.int64(18)}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 50
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "859d5552b1e58424"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-01T12:25:40.682267Z",
     "start_time": "2025-07-01T12:25:40.674539Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class DeepConvLSTM(nn.Module):\n",
    "    def __init__(self, num_channels, num_classes):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv1d(num_channels, 64, kernel_size=5, padding=2)\n",
    "        self.conv2 = nn.Conv1d(64, 128, kernel_size=5, padding=2)\n",
    "        self.conv3 = nn.Conv1d(128, 128, kernel_size=5, padding=2)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.pool = nn.MaxPool1d(2)\n",
    "        self.lstm = nn.LSTM(128, 128, num_layers=2, batch_first=True)\n",
    "        self.fc = nn.Linear(128, num_classes)\n",
    "    def forward(self, x):\n",
    "        x = x.permute(0, 2, 1)\n",
    "        x = self.relu(self.conv1(x)); x = self.pool(x)\n",
    "        x = self.relu(self.conv2(x)); x = self.pool(x)\n",
    "        x = self.relu(self.conv3(x)); x = self.pool(x)\n",
    "        x = x.permute(0, 2, 1)\n",
    "        out, _ = self.lstm(x)\n",
    "        return self.fc(out[:, -1, :])"
   ],
   "id": "be01bd41d45d14f4",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-01T12:25:40.807888Z",
     "start_time": "2025-07-01T12:25:40.774374Z"
    }
   },
   "cell_type": "code",
   "source": "model = DeepConvLSTM(d, num_classes).to(device)",
   "id": "c8e9e6fde95018c6",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-01T12:25:43.158006Z",
     "start_time": "2025-07-01T12:25:41.476401Z"
    }
   },
   "cell_type": "code",
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "EPOCHS = 20"
   ],
   "id": "7e67308041c9230",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-01T12:30:21.941559Z",
     "start_time": "2025-07-01T12:25:45.118036Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_losses, val_losses = [], []\n",
    "for epoch in range(1, EPOCHS+1):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    for Xb, yb in train_loader:\n",
    "        Xb, yb = Xb.to(device), yb.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        preds = model(Xb)\n",
    "        loss = criterion(preds, yb)\n",
    "        loss.backward(); optimizer.step()\n",
    "        train_loss += loss.item()*Xb.size(0)\n",
    "    train_losses.append(train_loss/len(train_loader.dataset))\n",
    "\n",
    "    model.eval()\n",
    "    val_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for Xb, yb in val_loader:\n",
    "            Xb, yb = Xb.to(device), yb.to(device)\n",
    "            preds = model(Xb)\n",
    "            val_loss += criterion(preds, yb).item()*Xb.size(0)\n",
    "            correct += (preds.argmax(1)==yb).sum().item()\n",
    "    val_losses.append(val_loss/len(val_loader.dataset))\n",
    "    print(f\"Epoch {epoch}/{EPOCHS} - Train: {train_losses[-1]:.4f}, Val: {val_losses[-1]:.4f}, Acc: {correct/len(val_loader.dataset):.4f}\")\n"
   ],
   "id": "8f24df6148c340f0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20 - Train: 0.8683, Val: 0.4184, Acc: 0.8614\n",
      "Epoch 2/20 - Train: 0.3794, Val: 0.3715, Acc: 0.8753\n",
      "Epoch 3/20 - Train: 0.2827, Val: 0.2601, Acc: 0.9188\n",
      "Epoch 4/20 - Train: 0.2295, Val: 0.1852, Acc: 0.9398\n",
      "Epoch 5/20 - Train: 0.1935, Val: 0.1723, Acc: 0.9437\n",
      "Epoch 6/20 - Train: 0.1652, Val: 0.1896, Acc: 0.9414\n",
      "Epoch 7/20 - Train: 0.1580, Val: 0.1713, Acc: 0.9472\n",
      "Epoch 8/20 - Train: 0.1306, Val: 0.1531, Acc: 0.9553\n",
      "Epoch 9/20 - Train: 0.1217, Val: 0.1254, Acc: 0.9621\n",
      "Epoch 10/20 - Train: 0.1174, Val: 0.1555, Acc: 0.9520\n",
      "Epoch 11/20 - Train: 0.1083, Val: 0.1292, Acc: 0.9606\n",
      "Epoch 12/20 - Train: 0.0981, Val: 0.1356, Acc: 0.9588\n",
      "Epoch 13/20 - Train: 0.0831, Val: 0.1333, Acc: 0.9585\n",
      "Epoch 14/20 - Train: 0.0826, Val: 0.1274, Acc: 0.9567\n",
      "Epoch 15/20 - Train: 0.0709, Val: 0.1245, Acc: 0.9602\n",
      "Epoch 16/20 - Train: 0.0755, Val: 0.1263, Acc: 0.9592\n",
      "Epoch 17/20 - Train: 0.0734, Val: 0.1100, Acc: 0.9655\n",
      "Epoch 18/20 - Train: 0.0674, Val: 0.1179, Acc: 0.9604\n",
      "Epoch 19/20 - Train: 0.0724, Val: 0.1285, Acc: 0.9624\n",
      "Epoch 20/20 - Train: 0.0496, Val: 0.1127, Acc: 0.9651\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-01T12:30:27.785131Z",
     "start_time": "2025-07-01T12:30:27.542259Z"
    }
   },
   "cell_type": "code",
   "source": [
    "plt.figure()\n",
    "plt.plot(range(1, EPOCHS+1), train_losses, label='Train Loss')\n",
    "plt.plot(range(1, EPOCHS+1), val_losses, label='Val Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.title('Train/Val Loss')\n",
    "plt.show()"
   ],
   "id": "a92fdfb93c123ba3",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-01T12:30:32.744481Z",
     "start_time": "2025-07-01T12:30:30.701548Z"
    }
   },
   "cell_type": "code",
   "source": [
    "test_df = pd.read_csv(\"data/test.csv\", low_memory=False)\n",
    "test_df"
   ],
   "id": "78ba20a4f3c9b6b0",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "          id  sbj_id sensor_location  \\\n",
       "0          0      22       right_arm   \n",
       "1          1      22       right_arm   \n",
       "2          2      23       right_arm   \n",
       "3          3      23       right_arm   \n",
       "4          4      23       right_arm   \n",
       "...      ...     ...             ...   \n",
       "48931  48931      23        left_leg   \n",
       "48932  48932      25        left_leg   \n",
       "48933  48933      24        left_leg   \n",
       "48934  48934      23        left_leg   \n",
       "48935  48935      23        left_leg   \n",
       "\n",
       "                                                  x_axis  \\\n",
       "0      [0.2428425714285714, 0.2134530714285714, 0.174...   \n",
       "1      [0.6752909910531751, 0.4247757439107542, 0.715...   \n",
       "2      [0.04528874289978267, 0.02636863686942854, -0....   \n",
       "3      [-0.4294609406487871, -0.6656510068112931, -0....   \n",
       "4      [2.476312835574577, 1.6733647285880453, 1.7557...   \n",
       "...                                                  ...   \n",
       "48931  [1.0630785714285715, 1.0709205714285714, 0.933...   \n",
       "48932  [0.834704380952381, 0.9560397142857142, 0.7693...   \n",
       "48933  [1.060091142857143, 1.0703054285714286, 1.0746...   \n",
       "48934  [-0.9559132857142858, -0.0778062857142857, -0....   \n",
       "48935  [0.97765, 0.9826858571428572, 0.98731071428571...   \n",
       "\n",
       "                                                  y_axis  \\\n",
       "0      [0.8463437142857143, 0.854221738095238, 0.8428...   \n",
       "1      [-0.9366750995461923, -0.6223881559309377, -0....   \n",
       "2      [0.5794056316368844, 0.5853422923083632, 0.646...   \n",
       "3      [-0.147632980836954, -0.014413570611691117, -0...   \n",
       "4      [-0.5983137218068052, -0.10164738944146791, -0...   \n",
       "...                                                  ...   \n",
       "48931  [0.1038264761904761, 0.1515437142857142, 0.190...   \n",
       "48932  [0.4938431904761905, -0.2392702857142856, -0.9...   \n",
       "48933  [0.0607051428571428, 0.0170856904761904, 0.008...   \n",
       "48934  [-0.5109039047619047, 2.9042674285714285, 0.89...   \n",
       "48935  [-0.185416, -0.1850214761904762, -0.1988123809...   \n",
       "\n",
       "                                                  z_axis  \n",
       "0      [-0.4574545714285714, -0.4578691904761905, -0....  \n",
       "1      [-0.6175092749440796, -0.5824192453686647, -0....  \n",
       "2      [0.5778143538332879, 0.5922718075175648, 0.873...  \n",
       "3      [-1.0071089537700262, -0.8174943548296542, -0....  \n",
       "4      [-2.0541462483911856, -1.6842387016850981, -1....  \n",
       "...                                                  ...  \n",
       "48931  [0.4514348571428571, 0.4639102857142857, 0.422...  \n",
       "48932  [0.0447854047619047, -0.0320387142857142, -0.2...  \n",
       "48933  [-0.1507257142857143, -0.1675727857142857, -0....  \n",
       "48934  [0.1249424761904761, 0.2449837142857142, 0.542...  \n",
       "48935  [0.2495088571428571, 0.2521657142857142, 0.248...  \n",
       "\n",
       "[48936 rows x 6 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sbj_id</th>\n",
       "      <th>sensor_location</th>\n",
       "      <th>x_axis</th>\n",
       "      <th>y_axis</th>\n",
       "      <th>z_axis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>right_arm</td>\n",
       "      <td>[0.2428425714285714, 0.2134530714285714, 0.174...</td>\n",
       "      <td>[0.8463437142857143, 0.854221738095238, 0.8428...</td>\n",
       "      <td>[-0.4574545714285714, -0.4578691904761905, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>right_arm</td>\n",
       "      <td>[0.6752909910531751, 0.4247757439107542, 0.715...</td>\n",
       "      <td>[-0.9366750995461923, -0.6223881559309377, -0....</td>\n",
       "      <td>[-0.6175092749440796, -0.5824192453686647, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>23</td>\n",
       "      <td>right_arm</td>\n",
       "      <td>[0.04528874289978267, 0.02636863686942854, -0....</td>\n",
       "      <td>[0.5794056316368844, 0.5853422923083632, 0.646...</td>\n",
       "      <td>[0.5778143538332879, 0.5922718075175648, 0.873...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>23</td>\n",
       "      <td>right_arm</td>\n",
       "      <td>[-0.4294609406487871, -0.6656510068112931, -0....</td>\n",
       "      <td>[-0.147632980836954, -0.014413570611691117, -0...</td>\n",
       "      <td>[-1.0071089537700262, -0.8174943548296542, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>23</td>\n",
       "      <td>right_arm</td>\n",
       "      <td>[2.476312835574577, 1.6733647285880453, 1.7557...</td>\n",
       "      <td>[-0.5983137218068052, -0.10164738944146791, -0...</td>\n",
       "      <td>[-2.0541462483911856, -1.6842387016850981, -1....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48931</th>\n",
       "      <td>48931</td>\n",
       "      <td>23</td>\n",
       "      <td>left_leg</td>\n",
       "      <td>[1.0630785714285715, 1.0709205714285714, 0.933...</td>\n",
       "      <td>[0.1038264761904761, 0.1515437142857142, 0.190...</td>\n",
       "      <td>[0.4514348571428571, 0.4639102857142857, 0.422...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48932</th>\n",
       "      <td>48932</td>\n",
       "      <td>25</td>\n",
       "      <td>left_leg</td>\n",
       "      <td>[0.834704380952381, 0.9560397142857142, 0.7693...</td>\n",
       "      <td>[0.4938431904761905, -0.2392702857142856, -0.9...</td>\n",
       "      <td>[0.0447854047619047, -0.0320387142857142, -0.2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48933</th>\n",
       "      <td>48933</td>\n",
       "      <td>24</td>\n",
       "      <td>left_leg</td>\n",
       "      <td>[1.060091142857143, 1.0703054285714286, 1.0746...</td>\n",
       "      <td>[0.0607051428571428, 0.0170856904761904, 0.008...</td>\n",
       "      <td>[-0.1507257142857143, -0.1675727857142857, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48934</th>\n",
       "      <td>48934</td>\n",
       "      <td>23</td>\n",
       "      <td>left_leg</td>\n",
       "      <td>[-0.9559132857142858, -0.0778062857142857, -0....</td>\n",
       "      <td>[-0.5109039047619047, 2.9042674285714285, 0.89...</td>\n",
       "      <td>[0.1249424761904761, 0.2449837142857142, 0.542...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48935</th>\n",
       "      <td>48935</td>\n",
       "      <td>23</td>\n",
       "      <td>left_leg</td>\n",
       "      <td>[0.97765, 0.9826858571428572, 0.98731071428571...</td>\n",
       "      <td>[-0.185416, -0.1850214761904762, -0.1988123809...</td>\n",
       "      <td>[0.2495088571428571, 0.2521657142857142, 0.248...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>48936 rows × 6 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-19T21:18:34.786554Z",
     "start_time": "2025-06-19T21:18:34.216226Z"
    }
   },
   "cell_type": "code",
   "source": [
    "pivot_df = test_df.pivot(index='id', columns='sensor_location', values=['x_axis','y_axis','z_axis'])\n",
    "# Namen angleichen → {loc}_{axis} (ohne \"_acc\"-Suffix)\n",
    "new_cols = []\n",
    "for axis, loc in pivot_df.columns:\n",
    "    axis_short = axis[0]  # x_axis -> x, y_axis -> y, z_axis -> z\n",
    "    if loc.endswith('_acc'):\n",
    "        col_name = f\"{loc}_{axis_short}\"\n",
    "    else:\n",
    "        col_name = f\"{loc}_acc_{axis_short}\"  # füge _acc hinzu, wenn im Train so benannt\n",
    "    new_cols.append(col_name)\n",
    "pivot_df.columns = new_cols\n",
    "pivot_df = pivot_df.reset_index()\n",
    "print(\"Spalten nach Pivot:\", pivot_df.columns.tolist()[:10])\n",
    "\n",
    "# Basismatrix mit allen Train-Sensor-Spalten (fehlende Sensoren = 0)\n",
    "base_test = pd.DataFrame(0, index=pivot_df.index, columns=sensor_cols)\n",
    "# Überschneidung füllen\n",
    "for col in sensor_cols:\n",
    "    if col in pivot_df.columns:\n",
    "        base_test[col] = pivot_df[col]\n",
    "\n",
    "# Skalierung\n",
    "base_test[sensor_cols] = scaler.transform(base_test[sensor_cols])\n",
    "base_test['id'] = pivot_df['id']\n",
    "\n",
    "# Sequenzen erzeugen\n",
    "values = base_test[sensor_cols].values\n",
    "ids = base_test['id'].values\n",
    "sequences, seq_ids = [], []\n",
    "for i in range(0, len(base_test) - WINDOW_SIZE + 1, STEP_SIZE):\n",
    "    sequences.append(values[i:i+WINDOW_SIZE])\n",
    "    seq_ids.append(ids[i])\n",
    "X_test = torch.tensor(np.array(sequences), dtype=torch.float32).to(device)\n",
    "print(f\"X_test shape: {X_test.shape}\")\n",
    "data_test = pivot_df.dropna(subset=test_cols).reset_index(drop=True)\n",
    "\n",
    "# Skalierung\n",
    "data_test[test_cols] = scaler.transform(data_test[test_cols])\n",
    "\n",
    "# Sequenzen erzeugen anhand fortlaufender id-Reihenfolge\n",
    "# Hier nutzen wir den index in pivot_df als Zeit\n",
    "values = data_test[test_cols].values\n",
    "ids = data_test['id'].values\n",
    "sequences, seq_ids = [], []\n",
    "for i in range(0, len(data_test) - WINDOW_SIZE + 1, STEP_SIZE):\n",
    "    seq = values[i:i+WINDOW_SIZE]\n",
    "    sequences.append(seq)\n",
    "    seq_ids.append(ids[i])\n",
    "X_test = torch.tensor(np.array(sequences), dtype=torch.float32).to(device)\n",
    "print(f\"X_test shape: {X_test.shape}\")\n",
    "\n",
    "# Vorhersagen\n",
    "model.eval()\n",
    "preds = []\n",
    "with torch.no_grad():\n",
    "    for xb in DataLoader(X_test, batch_size=batch_size):\n",
    "        logits = model(xb)\n",
    "        preds.extend(logits.argmax(dim=1).cpu().numpy())\n"
   ],
   "id": "a47af48c94efc1ff",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spalten nach Pivot: ['id', 'left_arm_acc_x', 'left_leg_acc_x', 'right_arm_acc_x', 'right_leg_acc_x', 'left_arm_acc_y', 'left_leg_acc_y', 'right_arm_acc_y', 'right_leg_acc_y', 'left_arm_acc_z']\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: '[0.2428425714285714, 0.2134530714285714, 0.1747093333333333, 0.1359561904761904, 0.1021450476190476, 0.0631573904761904, 0.0145962285714285, -0.0213671428571428, -0.0469919047619047, -0.0532688571428571, -0.0545326666666666, -0.0618505714285714, -0.0740160571428571, -0.0881772761904761, -0.0990204761904762, -0.1060097142857142, -0.1125049523809523, -0.1229300952380952, -0.1404117142857143, -0.1615804047619047, -0.1806195238095238, -0.198969619047619, -0.2177044761904762, -0.2330745904761904, -0.2477791, -0.2702355639097744, -0.2983505952380952, -0.3108898095238095, -0.3175154285714285, -0.3215467357142857, -0.3242848595238095, -0.3226944999999999, -0.3278828571428571, -0.3458519047619047, -0.3573982380952381, -0.3593672857142856, -0.3694402607142857, -0.3912872392857143, -0.4195397142857143, -0.4486532142857143, -0.4729640476190476, -0.481834225, -0.4717354416666667, -0.458918, -0.4592537142857142, -0.4719035714285714, -0.4851108571428571, -0.4967704, -0.5149714095238095, -0.5400368095238095]'",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mValueError\u001B[39m                                Traceback (most recent call last)",
      "\u001B[32m/tmp/ipykernel_2160445/4015796879.py\u001B[39m in \u001B[36m?\u001B[39m\u001B[34m()\u001B[39m\n\u001B[32m     19\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m col \u001B[38;5;28;01min\u001B[39;00m pivot_df.columns:\n\u001B[32m     20\u001B[39m         base_test[col] = pivot_df[col]\n\u001B[32m     21\u001B[39m \n\u001B[32m     22\u001B[39m \u001B[38;5;66;03m# Skalierung\u001B[39;00m\n\u001B[32m---> \u001B[39m\u001B[32m23\u001B[39m base_test[sensor_cols] = scaler.transform(base_test[sensor_cols])\n\u001B[32m     24\u001B[39m base_test[\u001B[33m'id'\u001B[39m] = pivot_df[\u001B[33m'id'\u001B[39m]\n\u001B[32m     25\u001B[39m \n\u001B[32m     26\u001B[39m \u001B[38;5;66;03m# Sequenzen erzeugen\u001B[39;00m\n",
      "\u001B[32m~/hasca-wear/venv/lib/python3.12/site-packages/sklearn/utils/_set_output.py\u001B[39m in \u001B[36m?\u001B[39m\u001B[34m(self, X, *args, **kwargs)\u001B[39m\n\u001B[32m    314\u001B[39m     @wraps(f)\n\u001B[32m    315\u001B[39m     \u001B[38;5;28;01mdef\u001B[39;00m wrapped(self, X, *args, **kwargs):\n\u001B[32m--> \u001B[39m\u001B[32m316\u001B[39m         data_to_wrap = f(self, X, *args, **kwargs)\n\u001B[32m    317\u001B[39m         \u001B[38;5;28;01mif\u001B[39;00m isinstance(data_to_wrap, tuple):\n\u001B[32m    318\u001B[39m             \u001B[38;5;66;03m# only wrap the first output for cross decomposition\u001B[39;00m\n\u001B[32m    319\u001B[39m             return_tuple = (\n",
      "\u001B[32m~/hasca-wear/venv/lib/python3.12/site-packages/sklearn/preprocessing/_data.py\u001B[39m in \u001B[36m?\u001B[39m\u001B[34m(self, X, copy)\u001B[39m\n\u001B[32m   1071\u001B[39m         \"\"\"\n\u001B[32m   1072\u001B[39m         check_is_fitted(self)\n\u001B[32m   1073\u001B[39m \n\u001B[32m   1074\u001B[39m         copy = copy \u001B[38;5;28;01mif\u001B[39;00m copy \u001B[38;5;28;01mis\u001B[39;00m \u001B[38;5;28;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m self.copy\n\u001B[32m-> \u001B[39m\u001B[32m1075\u001B[39m         X = validate_data(\n\u001B[32m   1076\u001B[39m             self,\n\u001B[32m   1077\u001B[39m             X,\n\u001B[32m   1078\u001B[39m             reset=\u001B[38;5;28;01mFalse\u001B[39;00m,\n",
      "\u001B[32m~/hasca-wear/venv/lib/python3.12/site-packages/sklearn/utils/validation.py\u001B[39m in \u001B[36m?\u001B[39m\u001B[34m(_estimator, X, y, reset, validate_separately, skip_check_array, **check_params)\u001B[39m\n\u001B[32m   2950\u001B[39m             out = y\n\u001B[32m   2951\u001B[39m         \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m   2952\u001B[39m             out = X, y\n\u001B[32m   2953\u001B[39m     \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28;01mnot\u001B[39;00m no_val_X \u001B[38;5;28;01mand\u001B[39;00m no_val_y:\n\u001B[32m-> \u001B[39m\u001B[32m2954\u001B[39m         out = check_array(X, input_name=\u001B[33m\"X\"\u001B[39m, **check_params)\n\u001B[32m   2955\u001B[39m     \u001B[38;5;28;01melif\u001B[39;00m no_val_X \u001B[38;5;28;01mand\u001B[39;00m \u001B[38;5;28;01mnot\u001B[39;00m no_val_y:\n\u001B[32m   2956\u001B[39m         out = _check_y(y, **check_params)\n\u001B[32m   2957\u001B[39m     \u001B[38;5;28;01melse\u001B[39;00m:\n",
      "\u001B[32m~/hasca-wear/venv/lib/python3.12/site-packages/sklearn/utils/validation.py\u001B[39m in \u001B[36m?\u001B[39m\u001B[34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_all_finite, ensure_non_negative, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001B[39m\n\u001B[32m   1050\u001B[39m                         )\n\u001B[32m   1051\u001B[39m                     array = xp.astype(array, dtype, copy=\u001B[38;5;28;01mFalse\u001B[39;00m)\n\u001B[32m   1052\u001B[39m                 \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m   1053\u001B[39m                     array = _asarray_with_order(array, order=order, dtype=dtype, xp=xp)\n\u001B[32m-> \u001B[39m\u001B[32m1054\u001B[39m             \u001B[38;5;28;01mexcept\u001B[39;00m ComplexWarning \u001B[38;5;28;01mas\u001B[39;00m complex_warning:\n\u001B[32m   1055\u001B[39m                 raise ValueError(\n\u001B[32m   1056\u001B[39m                     \u001B[33m\"Complex data not supported\\n{}\\n\"\u001B[39m.format(array)\n\u001B[32m   1057\u001B[39m                 ) \u001B[38;5;28;01mfrom\u001B[39;00m complex_warning\n",
      "\u001B[32m~/hasca-wear/venv/lib/python3.12/site-packages/sklearn/utils/_array_api.py\u001B[39m in \u001B[36m?\u001B[39m\u001B[34m(array, dtype, order, copy, xp, device)\u001B[39m\n\u001B[32m    753\u001B[39m         \u001B[38;5;66;03m# Use NumPy API to support order\u001B[39;00m\n\u001B[32m    754\u001B[39m         \u001B[38;5;28;01mif\u001B[39;00m copy \u001B[38;5;28;01mis\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m:\n\u001B[32m    755\u001B[39m             array = numpy.array(array, order=order, dtype=dtype)\n\u001B[32m    756\u001B[39m         \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m757\u001B[39m             array = numpy.asarray(array, order=order, dtype=dtype)\n\u001B[32m    758\u001B[39m \n\u001B[32m    759\u001B[39m         \u001B[38;5;66;03m# At this point array is a NumPy ndarray. We convert it to an array\u001B[39;00m\n\u001B[32m    760\u001B[39m         \u001B[38;5;66;03m# container that is consistent with the input's namespace.\u001B[39;00m\n",
      "\u001B[32m~/hasca-wear/venv/lib/python3.12/site-packages/pandas/core/generic.py\u001B[39m in \u001B[36m?\u001B[39m\u001B[34m(self, dtype, copy)\u001B[39m\n\u001B[32m   2164\u001B[39m             )\n\u001B[32m   2165\u001B[39m         values = self._values\n\u001B[32m   2166\u001B[39m         \u001B[38;5;28;01mif\u001B[39;00m copy \u001B[38;5;28;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m   2167\u001B[39m             \u001B[38;5;66;03m# Note: branch avoids `copy=None` for NumPy 1.x support\u001B[39;00m\n\u001B[32m-> \u001B[39m\u001B[32m2168\u001B[39m             arr = np.asarray(values, dtype=dtype)\n\u001B[32m   2169\u001B[39m         \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m   2170\u001B[39m             arr = np.array(values, dtype=dtype, copy=copy)\n\u001B[32m   2171\u001B[39m \n",
      "\u001B[31mValueError\u001B[39m: could not convert string to float: '[0.2428425714285714, 0.2134530714285714, 0.1747093333333333, 0.1359561904761904, 0.1021450476190476, 0.0631573904761904, 0.0145962285714285, -0.0213671428571428, -0.0469919047619047, -0.0532688571428571, -0.0545326666666666, -0.0618505714285714, -0.0740160571428571, -0.0881772761904761, -0.0990204761904762, -0.1060097142857142, -0.1125049523809523, -0.1229300952380952, -0.1404117142857143, -0.1615804047619047, -0.1806195238095238, -0.198969619047619, -0.2177044761904762, -0.2330745904761904, -0.2477791, -0.2702355639097744, -0.2983505952380952, -0.3108898095238095, -0.3175154285714285, -0.3215467357142857, -0.3242848595238095, -0.3226944999999999, -0.3278828571428571, -0.3458519047619047, -0.3573982380952381, -0.3593672857142856, -0.3694402607142857, -0.3912872392857143, -0.4195397142857143, -0.4486532142857143, -0.4729640476190476, -0.481834225, -0.4717354416666667, -0.458918, -0.4592537142857142, -0.4719035714285714, -0.4851108571428571, -0.4967704, -0.5149714095238095, -0.5400368095238095]'"
     ]
    }
   ],
   "execution_count": 68
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "817443321fab3486"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-01T13:32:23.604405Z",
     "start_time": "2025-07-01T13:00:24.432973Z"
    }
   },
   "cell_type": "code",
   "source": [
    "WINDOW_SIZE = 50\n",
    "STEP_SIZE = 25\n",
    "for i, df in enumerate([right_arm_df, left_arm_df, left_leg_df, right_leg_df]):\n",
    "    all_X, all_y = [], []\n",
    "    for subj in df['subject'].unique():\n",
    "        df_sub = df[df['subject'] == subj].reset_index(drop=True)\n",
    "        X_sub, y_sub = create_sequences(df_sub, [c for c in df.columns if c not in ['sbj_id', 'subject', 'label', 'label_code']], 'label_code', WINDOW_SIZE, STEP_SIZE)\n",
    "        all_X.append(X_sub)\n",
    "        all_y.append(y_sub)\n",
    "    X = np.vstack(all_X)\n",
    "    y = np.hstack(all_y)\n",
    "    print(f\"X shape: {X.shape}, y shape: {y.shape}\")\n",
    "\n",
    "    # Train/Test Split\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
    "\n",
    "    torch.manual_seed(42)\n",
    "    batch_size = 64\n",
    "    train_loader = DataLoader(SensorDataset(X_train, y_train), batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "    val_loader = DataLoader(SensorDataset(X_val, y_val), batch_size=batch_size)\n",
    "\n",
    "    d = 3\n",
    "    num_classes = 19#len(set(y))\n",
    "    model = DeepConvLSTM(d, num_classes).to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "    EPOCHS = 20\n",
    "    train_losses, val_losses = [], []\n",
    "    for epoch in range(1, EPOCHS+1):\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        for Xb, yb in train_loader:\n",
    "            Xb, yb = Xb.to(device), yb.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            preds = model(Xb)\n",
    "            loss = criterion(preds, yb)\n",
    "            loss.backward(); optimizer.step()\n",
    "            train_loss += loss.item()*Xb.size(0)\n",
    "        train_losses.append(train_loss/len(train_loader.dataset))\n",
    "\n",
    "        model.eval()\n",
    "        val_loss, correct = 0, 0\n",
    "        with torch.no_grad():\n",
    "            for Xb, yb in val_loader:\n",
    "                Xb, yb = Xb.to(device), yb.to(device)\n",
    "                preds = model(Xb)\n",
    "                val_loss += criterion(preds, yb).item()*Xb.size(0)\n",
    "                correct += (preds.argmax(1)==yb).sum().item()\n",
    "        val_losses.append(val_loss/len(val_loader.dataset))\n",
    "        print(f\"Epoch {epoch}/{EPOCHS} - Train: {train_losses[-1]:.4f}, Val: {val_losses[-1]:.4f}, Acc: {correct/len(val_loader.dataset):.4f}\")\n",
    "    torch.save(model, f\"models/DeepConvLSTM/{i}.pt\")\n",
    "\n",
    "\n",
    "\n"
   ],
   "id": "6c17222db032c055",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (82157, 50, 3), y shape: (82157,)\n",
      "Epoch 1/20 - Train: 1.3322, Val: 1.0470, Acc: 0.6400\n",
      "Epoch 2/20 - Train: 0.9855, Val: 0.9108, Acc: 0.6876\n",
      "Epoch 3/20 - Train: 0.8509, Val: 0.8160, Acc: 0.7171\n",
      "Epoch 4/20 - Train: 0.7631, Val: 0.7546, Acc: 0.7381\n",
      "Epoch 5/20 - Train: 0.6969, Val: 0.7081, Acc: 0.7554\n",
      "Epoch 6/20 - Train: 0.6440, Val: 0.6674, Acc: 0.7676\n",
      "Epoch 7/20 - Train: 0.5988, Val: 0.6735, Acc: 0.7682\n",
      "Epoch 8/20 - Train: 0.5607, Val: 0.6241, Acc: 0.7838\n",
      "Epoch 9/20 - Train: 0.5297, Val: 0.6151, Acc: 0.7820\n",
      "Epoch 10/20 - Train: 0.4950, Val: 0.6060, Acc: 0.7901\n",
      "Epoch 11/20 - Train: 0.4659, Val: 0.5813, Acc: 0.8011\n",
      "Epoch 12/20 - Train: 0.4396, Val: 0.5787, Acc: 0.8021\n",
      "Epoch 13/20 - Train: 0.4164, Val: 0.6025, Acc: 0.7975\n",
      "Epoch 14/20 - Train: 0.3910, Val: 0.5778, Acc: 0.8093\n",
      "Epoch 15/20 - Train: 0.3716, Val: 0.5669, Acc: 0.8160\n",
      "Epoch 16/20 - Train: 0.3483, Val: 0.5912, Acc: 0.8098\n",
      "Epoch 17/20 - Train: 0.3324, Val: 0.5896, Acc: 0.8101\n",
      "Epoch 18/20 - Train: 0.3133, Val: 0.6076, Acc: 0.8026\n",
      "Epoch 19/20 - Train: 0.3028, Val: 0.5943, Acc: 0.8137\n",
      "Epoch 20/20 - Train: 0.2859, Val: 0.5957, Acc: 0.8180\n",
      "X shape: (82157, 50, 3), y shape: (82157,)\n",
      "Epoch 1/20 - Train: 1.3295, Val: 1.0934, Acc: 0.6225\n",
      "Epoch 2/20 - Train: 0.9830, Val: 0.9625, Acc: 0.6660\n",
      "Epoch 3/20 - Train: 0.8526, Val: 0.8201, Acc: 0.7140\n",
      "Epoch 4/20 - Train: 0.7668, Val: 0.7580, Acc: 0.7394\n",
      "Epoch 5/20 - Train: 0.6942, Val: 0.6936, Acc: 0.7572\n",
      "Epoch 6/20 - Train: 0.6345, Val: 0.6981, Acc: 0.7566\n",
      "Epoch 7/20 - Train: 0.5892, Val: 0.6551, Acc: 0.7741\n",
      "Epoch 8/20 - Train: 0.5525, Val: 0.6260, Acc: 0.7837\n",
      "Epoch 9/20 - Train: 0.5155, Val: 0.6021, Acc: 0.7948\n",
      "Epoch 10/20 - Train: 0.4787, Val: 0.5914, Acc: 0.7976\n",
      "Epoch 11/20 - Train: 0.4519, Val: 0.6004, Acc: 0.7938\n",
      "Epoch 12/20 - Train: 0.4231, Val: 0.6005, Acc: 0.7958\n",
      "Epoch 13/20 - Train: 0.3991, Val: 0.5766, Acc: 0.8096\n",
      "Epoch 14/20 - Train: 0.3762, Val: 0.5782, Acc: 0.8077\n",
      "Epoch 15/20 - Train: 0.3562, Val: 0.5918, Acc: 0.8102\n",
      "Epoch 16/20 - Train: 0.3348, Val: 0.5879, Acc: 0.8099\n",
      "Epoch 17/20 - Train: 0.3196, Val: 0.6070, Acc: 0.8048\n",
      "Epoch 18/20 - Train: 0.2987, Val: 0.5925, Acc: 0.8118\n",
      "Epoch 19/20 - Train: 0.2866, Val: 0.5944, Acc: 0.8125\n",
      "Epoch 20/20 - Train: 0.2695, Val: 0.5931, Acc: 0.8208\n",
      "X shape: (82157, 50, 3), y shape: (82157,)\n",
      "Epoch 1/20 - Train: 1.2266, Val: 1.0165, Acc: 0.5985\n",
      "Epoch 2/20 - Train: 0.9441, Val: 0.8830, Acc: 0.6563\n",
      "Epoch 3/20 - Train: 0.8404, Val: 0.7975, Acc: 0.6790\n",
      "Epoch 4/20 - Train: 0.7783, Val: 0.7699, Acc: 0.6972\n",
      "Epoch 5/20 - Train: 0.7250, Val: 0.7262, Acc: 0.7122\n",
      "Epoch 6/20 - Train: 0.6881, Val: 0.7261, Acc: 0.7102\n",
      "Epoch 7/20 - Train: 0.6559, Val: 0.6812, Acc: 0.7280\n",
      "Epoch 8/20 - Train: 0.6230, Val: 0.6650, Acc: 0.7366\n",
      "Epoch 9/20 - Train: 0.5949, Val: 0.6529, Acc: 0.7390\n",
      "Epoch 10/20 - Train: 0.5669, Val: 0.6185, Acc: 0.7578\n",
      "Epoch 11/20 - Train: 0.5430, Val: 0.5952, Acc: 0.7658\n",
      "Epoch 12/20 - Train: 0.5210, Val: 0.5789, Acc: 0.7726\n",
      "Epoch 13/20 - Train: 0.5022, Val: 0.6133, Acc: 0.7659\n",
      "Epoch 14/20 - Train: 0.4761, Val: 0.6025, Acc: 0.7672\n",
      "Epoch 15/20 - Train: 0.4537, Val: 0.6103, Acc: 0.7654\n",
      "Epoch 16/20 - Train: 0.4355, Val: 0.5793, Acc: 0.7796\n",
      "Epoch 17/20 - Train: 0.4194, Val: 0.5847, Acc: 0.7812\n",
      "Epoch 18/20 - Train: 0.4009, Val: 0.6217, Acc: 0.7708\n",
      "Epoch 19/20 - Train: 0.3847, Val: 0.5842, Acc: 0.7880\n",
      "Epoch 20/20 - Train: 0.3689, Val: 0.5900, Acc: 0.7897\n",
      "X shape: (82157, 50, 3), y shape: (82157,)\n",
      "Epoch 1/20 - Train: 1.1614, Val: 0.9709, Acc: 0.6050\n",
      "Epoch 2/20 - Train: 0.9183, Val: 0.8760, Acc: 0.6357\n",
      "Epoch 3/20 - Train: 0.8251, Val: 0.7844, Acc: 0.6789\n",
      "Epoch 4/20 - Train: 0.7684, Val: 0.7729, Acc: 0.6860\n",
      "Epoch 5/20 - Train: 0.7217, Val: 0.7094, Acc: 0.7110\n",
      "Epoch 6/20 - Train: 0.6826, Val: 0.6763, Acc: 0.7263\n",
      "Epoch 7/20 - Train: 0.6481, Val: 0.6791, Acc: 0.7263\n",
      "Epoch 8/20 - Train: 0.6196, Val: 0.6597, Acc: 0.7389\n",
      "Epoch 9/20 - Train: 0.5921, Val: 0.6364, Acc: 0.7526\n",
      "Epoch 10/20 - Train: 0.5682, Val: 0.6211, Acc: 0.7533\n",
      "Epoch 11/20 - Train: 0.5441, Val: 0.6192, Acc: 0.7622\n",
      "Epoch 12/20 - Train: 0.5218, Val: 0.6057, Acc: 0.7714\n",
      "Epoch 13/20 - Train: 0.5008, Val: 0.5981, Acc: 0.7653\n",
      "Epoch 14/20 - Train: 0.4753, Val: 0.5820, Acc: 0.7733\n",
      "Epoch 15/20 - Train: 0.4591, Val: 0.5821, Acc: 0.7784\n",
      "Epoch 16/20 - Train: 0.4387, Val: 0.5948, Acc: 0.7778\n",
      "Epoch 17/20 - Train: 0.4255, Val: 0.5865, Acc: 0.7828\n",
      "Epoch 18/20 - Train: 0.4076, Val: 0.5814, Acc: 0.7852\n",
      "Epoch 19/20 - Train: 0.3898, Val: 0.5883, Acc: 0.7863\n",
      "Epoch 20/20 - Train: 0.3790, Val: 0.5912, Acc: 0.7861\n"
     ]
    }
   ],
   "execution_count": 23
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "fe4f099e6964c1e"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
