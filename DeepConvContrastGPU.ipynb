{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-07-02T22:05:09.641323Z",
     "start_time": "2025-07-02T22:05:03.755463Z"
    }
   },
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-02T22:05:09.766787Z",
     "start_time": "2025-07-02T22:05:09.760971Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def map_label(lbl):\n",
    "    mapping = {\n",
    "        'null': 0,\n",
    "        'jogging': 1,\n",
    "        'jogging (rotating arms)': 2,\n",
    "        'jogging (skipping)': 3,\n",
    "        'jogging (sidesteps)': 4,\n",
    "        'jogging (butt-kicks)': 5,\n",
    "        'stretching (triceps)': 6,\n",
    "        'stretching (lunging)': 7,\n",
    "        'stretching (shoulders)': 8,\n",
    "        'stretching (hamstrings)': 9,\n",
    "        'stretching (lumbar rotation)': 10,\n",
    "        'push-ups': 11,\n",
    "        'push-ups (complex)': 12,\n",
    "        'sit-ups': 13,\n",
    "        'sit-ups (complex)': 14,\n",
    "        'burpees': 15,\n",
    "        'lunges': 16,\n",
    "        'lunges (complex)': 17,\n",
    "        'bench-dips': 18\n",
    "    }\n",
    "    return mapping.get(lbl, np.nan)\n",
    "label_map = {\n",
    "    'null': 0,'jogging': 1,'jogging (rotating arms)': 2,'jogging (skipping)': 3,'jogging (sidesteps)': 4,'jogging (butt-kicks)': 5,\n",
    "    'stretching (triceps)': 6,'stretching (lunging)': 7,'stretching (shoulders)': 8,'stretching (hamstrings)': 9,'stretching (lumbar rotation)': 10,\n",
    "    'push-ups': 11,'push-ups (complex)': 12,'sit-ups': 13,'sit-ups (complex)': 14,'burpees': 15,'lunges': 16,'lunges (complex)': 17,'bench-dips': 18\n",
    "}"
   ],
   "id": "489c10a75fd263e9",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-02T22:05:11.830344Z",
     "start_time": "2025-07-02T22:05:11.821438Z"
    }
   },
   "cell_type": "code",
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")"
   ],
   "id": "a8c72f945b28c33e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-02T22:05:18.312624Z",
     "start_time": "2025-07-02T22:05:18.307637Z"
    }
   },
   "cell_type": "code",
   "source": [
    "data_dir = Path('data')\n",
    "train_dir = data_dir / 'train'\n",
    "meta_file = data_dir / 'meta_data.txt'\n",
    "test_file = data_dir/'test.csv'"
   ],
   "id": "14620b65809e956c",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-02T22:05:41.335761Z",
     "start_time": "2025-07-02T22:05:22.754941Z"
    }
   },
   "cell_type": "code",
   "source": [
    "sbj_files = sorted(train_dir.glob('sbj_*.csv'))\n",
    "dfs = []\n",
    "for f in sbj_files:\n",
    "    df = pd.read_csv(f,low_memory=False)\n",
    "    df['subject'] = df['sbj_id'].astype(str)\n",
    "    dfs.append(df)\n",
    "\n",
    "raw_df = pd.concat(dfs, ignore_index=True)\n"
   ],
   "id": "e55c347192a068fd",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-02T22:05:50.954047Z",
     "start_time": "2025-07-02T22:05:41.375998Z"
    }
   },
   "cell_type": "code",
   "source": [
    "raw_df['label_code'] = raw_df['label'].apply(map_label)\n",
    "raw_df = raw_df.dropna(subset=['label_code']).reset_index(drop=True)\n",
    "raw_df['label_code'] = raw_df['label_code'].astype(int)\n",
    "\n",
    "sensor_cols = [c for c in raw_df.columns if c not in ['sbj_id', 'subject', 'label', 'label_code']]\n",
    "raw_df = raw_df.dropna(subset=sensor_cols).reset_index(drop=True)\n",
    "scaler = StandardScaler()\n",
    "raw_df[sensor_cols] = scaler.fit_transform(raw_df[sensor_cols])"
   ],
   "id": "f9054cd986665ed0",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-02T22:05:50.995446Z",
     "start_time": "2025-07-02T22:05:50.990780Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def create_sequences(df, sensor_cols, target_col, window, step):\n",
    "    X, y = [], []\n",
    "    data = df[sensor_cols].values\n",
    "    labels = df[target_col].values\n",
    "    for start in range(0, len(df) - window + 1, step):\n",
    "        end = start + window\n",
    "        seq = data[start:end]\n",
    "        lab = np.bincount(labels[start:end]).argmax()\n",
    "        X.append(seq)\n",
    "        y.append(lab)\n",
    "    return np.array(X), np.array(y)"
   ],
   "id": "4b9c676a4aa0d699",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-02T22:05:51.066340Z",
     "start_time": "2025-07-02T22:05:51.060339Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class SensorDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = torch.tensor(X, dtype=torch.float32)\n",
    "        self.y = torch.tensor(y, dtype=torch.long)\n",
    "    def __len__(self): return len(self.X)\n",
    "    def __getitem__(self, idx): return self.X[idx], self.y[idx]"
   ],
   "id": "881e125c2e6930b5",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-02T22:05:52.126377Z",
     "start_time": "2025-07-02T22:05:52.115259Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def jitter(x, sigma=0.8):\n",
    "    return x + np.random.normal(loc=0., scale=sigma, size=x.shape)\n",
    "\n",
    "\n",
    "def scaling(x, sigma=1.1):\n",
    "    \"\"\"\n",
    "    Applies scaling to a 2D tensor of shape (sequence_length, features).\n",
    "    \"\"\"\n",
    "    # The factor should have the same shape as the input to allow for element-wise multiplication.\n",
    "    factor = np.random.normal(loc=1., scale=sigma, size=x.shape)\n",
    "    return x * factor\n",
    "\n",
    "class ContrastiveDataset(Dataset):\n",
    "    def __init__(self, X, y, transform=None):\n",
    "        self.X = torch.tensor(X, dtype=torch.float32)\n",
    "        self.y = torch.tensor(y, dtype=torch.long)\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x = self.X[idx]\n",
    "        y = self.y[idx]\n",
    "\n",
    "        # Apply two different augmentations\n",
    "        x1 = torch.tensor(jitter(x.numpy()), dtype=torch.float32)\n",
    "        x2 = torch.tensor(scaling(x.numpy()), dtype=torch.float32)\n",
    "\n",
    "        return x1, x2, y"
   ],
   "id": "cb657f0ca05f1549",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-02T22:05:56.653996Z",
     "start_time": "2025-07-02T22:05:56.638963Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class NTXentLoss(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, device, batch_size, temperature=0.1, use_cosine_similarity=True):\n",
    "        super(NTXentLoss, self).__init__()\n",
    "        self.batch_size = batch_size\n",
    "        self.temperature = temperature\n",
    "        self.device = device\n",
    "        self.softmax = torch.nn.Softmax(dim=-1)\n",
    "        self.mask_samples_from_same_repr = self._get_correlated_mask().type(torch.bool)\n",
    "        self.similarity_function = self._get_similarity_function(use_cosine_similarity)\n",
    "        self.criterion = torch.nn.CrossEntropyLoss(reduction=\"sum\")\n",
    "\n",
    "    def _get_similarity_function(self, use_cosine_similarity):\n",
    "        if use_cosine_similarity:\n",
    "            self._cosine_similarity = torch.nn.CosineSimilarity(dim=-1)\n",
    "            return self._cosine_simililarity\n",
    "        else:\n",
    "            return self._dot_simililarity\n",
    "\n",
    "    def _get_correlated_mask(self):\n",
    "        diag = np.eye(2 * self.batch_size)\n",
    "        l1 = np.eye((2 * self.batch_size), 2 * self.batch_size, k=-self.batch_size)\n",
    "        l2 = np.eye((2 * self.batch_size), 2 * self.batch_size, k=self.batch_size)\n",
    "        mask = torch.from_numpy((diag + l1 + l2))\n",
    "        mask = (1 - mask).type(torch.bool)\n",
    "        return mask.to(self.device)\n",
    "\n",
    "    @staticmethod\n",
    "    def _dot_simililarity(x, y):\n",
    "        v = torch.tensordot(x.unsqueeze(1), y.T.unsqueeze(0), dims=2)\n",
    "        return v\n",
    "\n",
    "    def _cosine_simililarity(self, x, y):\n",
    "        v = self._cosine_similarity(x.unsqueeze(1), y.unsqueeze(0))\n",
    "        return v\n",
    "\n",
    "    def forward(self, zis, zjs):\n",
    "        representations = torch.cat([zjs, zis], dim=0)\n",
    "        similarity_matrix = self.similarity_function(representations, representations)\n",
    "        l_pos = torch.diag(similarity_matrix, self.batch_size)\n",
    "        r_pos = torch.diag(similarity_matrix, -self.batch_size)\n",
    "        positives = torch.cat([l_pos, r_pos]).view(2 * self.batch_size, 1)\n",
    "        negatives = similarity_matrix[self.mask_samples_from_same_repr].view(2 * self.batch_size, -1)\n",
    "        logits = torch.cat((positives, negatives), dim=1)\n",
    "        logits /= self.temperature\n",
    "        labels = torch.zeros(2 * self.batch_size).to(self.device).long()\n",
    "        loss = self.criterion(logits, labels)\n",
    "        return loss / (2 * self.batch_size)"
   ],
   "id": "4a2cb40961bd01b",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-02T22:06:01.714331Z",
     "start_time": "2025-07-02T22:06:01.705872Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class DeepConvLSTM_contrastive(nn.Module):\n",
    "    def __init__(self, num_channels, embedding_dim=128):\n",
    "        super().__init__()\n",
    "        # Backbone\n",
    "        self.conv1 = nn.Conv1d(num_channels, 64, kernel_size=5, padding=2)\n",
    "        self.conv2 = nn.Conv1d(64, 128, kernel_size=5, padding=2)\n",
    "        self.conv3 = nn.Conv1d(128, 128, kernel_size=5, padding=2)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.pool = nn.MaxPool1d(2)\n",
    "        self.lstm = nn.LSTM(128, 128, num_layers=2, batch_first=True)\n",
    "\n",
    "        # Projection Head\n",
    "        self.projection = nn.Sequential(\n",
    "            nn.Linear(128, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, embedding_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Backbone forward pass\n",
    "        x = x.permute(0, 2, 1)\n",
    "        x = self.relu(self.conv1(x)); x = self.pool(x)\n",
    "        x = self.relu(self.conv2(x)); x = self.pool(x)\n",
    "        x = self.relu(self.conv3(x)); x = self.pool(x)\n",
    "        x = x.permute(0, 2, 1)\n",
    "        out, _ = self.lstm(x)\n",
    "        features = out[:, -1, :]\n",
    "\n",
    "        # Projection head forward pass\n",
    "        projection = self.projection(features)\n",
    "\n",
    "        return features, projection"
   ],
   "id": "45d190927f7c902f",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-02T22:06:18.500681Z",
     "start_time": "2025-07-02T22:06:18.494054Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "class DeepMLPClassifier(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim_1, hidden_dim_2, num_classes, dropout_rate=0.5):\n",
    "        super().__init__()\n",
    "        self.network = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim_1),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(hidden_dim_1, hidden_dim_2),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(hidden_dim_2, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.network(x)\n"
   ],
   "id": "aedcb4612051042e",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-02T22:06:25.120223Z",
     "start_time": "2025-07-02T22:06:24.392536Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "raw_df_filtered = raw_df[raw_df['label_code'] != 0].copy()\n",
    "\n",
    "# Create a new mapping for the remaining labels (1-18 -> 0-17)\n",
    "# This is crucial for the model's loss function\n",
    "original_labels = sorted(raw_df_filtered['label_code'].unique())\n",
    "label_remapping = {orig_label: new_label for new_label, orig_label in enumerate(original_labels)}\n",
    "raw_df_filtered['remapped_label'] = raw_df_filtered['label_code'].map(label_remapping)\n",
    "right_arm_df = raw_df_filtered[[\"right_arm_acc_x\", \"right_arm_acc_y\", \"right_arm_acc_z\", \"subject\", \"remapped_label\"]]\n",
    "left_arm_df = raw_df_filtered[[\"left_arm_acc_x\", \"left_arm_acc_y\", \"left_arm_acc_z\", \"subject\", \"remapped_label\"]]\n",
    "right_leg_df = raw_df_filtered[[\"right_leg_acc_x\", \"right_leg_acc_y\", \"right_leg_acc_z\", \"subject\", \"remapped_label\"]]\n",
    "left_leg_df = raw_df_filtered[[\"left_leg_acc_x\", \"left_leg_acc_y\", \"left_leg_acc_z\", \"subject\", \"remapped_label\"]]\n"
   ],
   "id": "b1384ce80fd5b54a",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-02T22:29:21.914092Z",
     "start_time": "2025-07-02T22:06:39.413692Z"
    }
   },
   "cell_type": "code",
   "source": [
    "WINDOW_SIZE = 50\n",
    "STEP_SIZE = 25\n",
    "for i, df in enumerate([right_arm_df, left_arm_df, left_leg_df, right_leg_df]):\n",
    "    all_X, all_y = [], []\n",
    "    for subj in df['subject'].unique():\n",
    "        df_sub = df[df['subject'] == subj].reset_index(drop=True)\n",
    "        X_sub, y_sub = create_sequences(df_sub, [c for c in df.columns if c not in ['sbj_id', 'subject', 'label', 'label_code', 'remapped_label']], 'remapped_label', WINDOW_SIZE, STEP_SIZE)\n",
    "        all_X.append(X_sub)\n",
    "        all_y.append(y_sub)\n",
    "    X = np.vstack(all_X)\n",
    "    y = np.hstack(all_y)\n",
    "    print(f\"X shape: {X.shape}, y shape: {y.shape}\")\n",
    "\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
    "\n",
    "    torch.manual_seed(42)\n",
    "    batch_size = 64\n",
    "    train_loader = DataLoader(SensorDataset(X_train, y_train), batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "    val_loader = DataLoader(SensorDataset(X_val, y_val), batch_size=batch_size)\n",
    "\n",
    "    d = 3\n",
    "    num_classes = 18\n",
    "    contrastive_loader = DataLoader(ContrastiveDataset(X_train, y_train), batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "\n",
    "    contrastive_model = DeepConvLSTM_contrastive(d).to(device)\n",
    "    contrastive_optimizer = torch.optim.Adam(contrastive_model.parameters(), lr=1e-3)\n",
    "    contrastive_criterion = NTXentLoss(device=device, batch_size=batch_size, temperature=0.5)\n",
    "\n",
    "    CONTRASTIVE_EPOCHS = 10\n",
    "    for epoch in range(1, CONTRASTIVE_EPOCHS + 1):\n",
    "        contrastive_model.train()\n",
    "        total_loss = 0\n",
    "        for x1, x2, _ in tqdm(contrastive_loader, desc=f\"Epoch {epoch}\"):\n",
    "            x1, x2 = x1.to(device), x2.to(device)\n",
    "\n",
    "            contrastive_optimizer.zero_grad()\n",
    "\n",
    "            _, proj1 = contrastive_model(x1)\n",
    "            _, proj2 = contrastive_model(x2)\n",
    "\n",
    "            loss = contrastive_criterion(proj1, proj2)\n",
    "\n",
    "            loss.backward()\n",
    "            contrastive_optimizer.step()\n",
    "\n",
    "            total_loss += loss.item() * x1.size(0)\n",
    "\n",
    "        avg_loss = total_loss / len(contrastive_loader.dataset)\n",
    "        print(f\"Epoch {epoch}/{CONTRASTIVE_EPOCHS} - Contrastive Loss: {avg_loss:.4f}\")\n",
    "\n",
    "    for param in contrastive_model.parameters():\n",
    "        param.requires_grad = False\n",
    "\n",
    "    # Use the new DeepMLPClassifier\n",
    "    classifier = DeepMLPClassifier(\n",
    "        input_dim=128,\n",
    "        hidden_dim_1=256,\n",
    "        hidden_dim_2=128,\n",
    "        num_classes=num_classes\n",
    "    ).to(device)\n",
    "\n",
    "    classifier_optimizer = torch.optim.Adam(classifier.parameters(), lr=1e-3)\n",
    "    classifier_criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    FINETUNE_EPOCHS = 20\n",
    "\n",
    "    train_losses, val_losses = [], []\n",
    "    for epoch in range(1, FINETUNE_EPOCHS + 1):\n",
    "        contrastive_model.eval() # Backbone is in eval mode\n",
    "        classifier.train()       # Classifier is in train mode\n",
    "        train_loss = 0\n",
    "        for Xb, yb in train_loader:\n",
    "            Xb, yb = Xb.to(device), yb.to(device)\n",
    "            classifier_optimizer.zero_grad()\n",
    "\n",
    "            # Get features from the frozen contrastive model\n",
    "            # The permute operation is correctly handled inside its forward pass\n",
    "            with torch.no_grad():\n",
    "                features, _ = contrastive_model(Xb)\n",
    "\n",
    "            # Train the classifier\n",
    "            preds = classifier(features)\n",
    "            loss = classifier_criterion(preds, yb)\n",
    "            loss.backward()\n",
    "            classifier_optimizer.step()\n",
    "            train_loss += loss.item() * Xb.size(0)\n",
    "        train_losses.append(train_loss / len(train_loader.dataset))\n",
    "\n",
    "        contrastive_model.eval()\n",
    "        classifier.eval()\n",
    "        val_loss, correct = 0, 0\n",
    "        with torch.no_grad():\n",
    "            for Xb, yb in val_loader:\n",
    "                Xb, yb = Xb.to(device), yb.to(device)\n",
    "                features, _ = contrastive_model(Xb)\n",
    "                preds = classifier(features)\n",
    "                val_loss += classifier_criterion(preds, yb).item() * Xb.size(0)\n",
    "                correct += (preds.argmax(1) == yb).sum().item()\n",
    "        val_losses.append(val_loss / len(val_loader.dataset))\n",
    "        print(f\"Epoch {epoch}/{FINETUNE_EPOCHS} - Train: {train_losses[-1]:.4f}, Val: {val_losses[-1]:.4f}, Acc: {correct / len(val_loader.dataset):.4f}\")\n",
    "    torch.save(contrastive_model, f\"models/DeepConvContrast/2_{i}_contrast.pt\")\n",
    "    torch.save(classifier, f\"models/DeepConvContrast/2_{i}_classifier.pt\")\n",
    "\n",
    "\n"
   ],
   "id": "b5283effe513944a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (82157, 50, 3), y shape: (82157,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 1026/1026 [01:16<00:00, 13.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 - Contrastive Loss: 3.2431\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 1026/1026 [01:16<00:00, 13.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/10 - Contrastive Loss: 3.1600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 1026/1026 [01:11<00:00, 14.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/10 - Contrastive Loss: 3.1413\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 1026/1026 [01:12<00:00, 14.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/10 - Contrastive Loss: 3.1322\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 1026/1026 [01:13<00:00, 13.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10 - Contrastive Loss: 3.1256\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|██████████| 1026/1026 [01:12<00:00, 14.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/10 - Contrastive Loss: 3.1204\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|██████████| 1026/1026 [01:12<00:00, 14.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/10 - Contrastive Loss: 3.1176\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|██████████| 1026/1026 [01:11<00:00, 14.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/10 - Contrastive Loss: 3.1138\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 1026/1026 [01:11<00:00, 14.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/10 - Contrastive Loss: 3.1119\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10: 100%|██████████| 1026/1026 [01:12<00:00, 14.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/10 - Contrastive Loss: 3.1095\n",
      "Epoch 1/20 - Train: 1.4626, Val: 1.1847, Acc: 0.5896\n",
      "Epoch 2/20 - Train: 1.2597, Val: 1.1217, Acc: 0.6042\n",
      "Epoch 3/20 - Train: 1.2104, Val: 1.0780, Acc: 0.6162\n",
      "Epoch 4/20 - Train: 1.1719, Val: 1.0500, Acc: 0.6275\n",
      "Epoch 5/20 - Train: 1.1452, Val: 1.0287, Acc: 0.6363\n",
      "Epoch 6/20 - Train: 1.1279, Val: 1.0110, Acc: 0.6431\n",
      "Epoch 7/20 - Train: 1.1118, Val: 1.0006, Acc: 0.6461\n",
      "Epoch 8/20 - Train: 1.0989, Val: 0.9891, Acc: 0.6512\n",
      "Epoch 9/20 - Train: 1.0874, Val: 0.9766, Acc: 0.6569\n",
      "Epoch 10/20 - Train: 1.0748, Val: 0.9639, Acc: 0.6587\n",
      "Epoch 11/20 - Train: 1.0688, Val: 0.9604, Acc: 0.6619\n",
      "Epoch 12/20 - Train: 1.0606, Val: 0.9537, Acc: 0.6666\n",
      "Epoch 13/20 - Train: 1.0559, Val: 0.9500, Acc: 0.6700\n",
      "Epoch 14/20 - Train: 1.0485, Val: 0.9381, Acc: 0.6644\n",
      "Epoch 15/20 - Train: 1.0443, Val: 0.9333, Acc: 0.6678\n",
      "Epoch 16/20 - Train: 1.0405, Val: 0.9377, Acc: 0.6690\n",
      "Epoch 17/20 - Train: 1.0341, Val: 0.9312, Acc: 0.6715\n",
      "Epoch 18/20 - Train: 1.0254, Val: 0.9231, Acc: 0.6768\n",
      "Epoch 19/20 - Train: 1.0237, Val: 0.9235, Acc: 0.6770\n",
      "Epoch 20/20 - Train: 1.0224, Val: 0.9188, Acc: 0.6793\n",
      "X shape: (82157, 50, 3), y shape: (82157,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 1026/1026 [01:05<00:00, 15.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 - Contrastive Loss: 3.2537\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 1026/1026 [01:03<00:00, 16.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/10 - Contrastive Loss: 3.1587\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 1026/1026 [01:01<00:00, 16.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/10 - Contrastive Loss: 3.1432\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 1026/1026 [01:07<00:00, 15.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/10 - Contrastive Loss: 3.1357\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 1026/1026 [01:06<00:00, 15.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10 - Contrastive Loss: 3.1287\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|██████████| 1026/1026 [01:02<00:00, 16.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/10 - Contrastive Loss: 3.1230\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7:  83%|████████▎ | 847/1026 [00:52<00:11, 16.08it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mKeyboardInterrupt\u001B[39m                         Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[14]\u001B[39m\u001B[32m, line 43\u001B[39m\n\u001B[32m     39\u001B[39m _, proj2 = contrastive_model(x2)\n\u001B[32m     41\u001B[39m loss = contrastive_criterion(proj1, proj2)\n\u001B[32m---> \u001B[39m\u001B[32m43\u001B[39m \u001B[43mloss\u001B[49m\u001B[43m.\u001B[49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     44\u001B[39m contrastive_optimizer.step()\n\u001B[32m     46\u001B[39m total_loss += loss.item() * x1.size(\u001B[32m0\u001B[39m)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Dokumente/Projekte/hasca-wear/venv/lib/python3.12/site-packages/torch/_tensor.py:648\u001B[39m, in \u001B[36mTensor.backward\u001B[39m\u001B[34m(self, gradient, retain_graph, create_graph, inputs)\u001B[39m\n\u001B[32m    638\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m has_torch_function_unary(\u001B[38;5;28mself\u001B[39m):\n\u001B[32m    639\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m handle_torch_function(\n\u001B[32m    640\u001B[39m         Tensor.backward,\n\u001B[32m    641\u001B[39m         (\u001B[38;5;28mself\u001B[39m,),\n\u001B[32m   (...)\u001B[39m\u001B[32m    646\u001B[39m         inputs=inputs,\n\u001B[32m    647\u001B[39m     )\n\u001B[32m--> \u001B[39m\u001B[32m648\u001B[39m \u001B[43mtorch\u001B[49m\u001B[43m.\u001B[49m\u001B[43mautograd\u001B[49m\u001B[43m.\u001B[49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    649\u001B[39m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgradient\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m=\u001B[49m\u001B[43minputs\u001B[49m\n\u001B[32m    650\u001B[39m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Dokumente/Projekte/hasca-wear/venv/lib/python3.12/site-packages/torch/autograd/__init__.py:353\u001B[39m, in \u001B[36mbackward\u001B[39m\u001B[34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001B[39m\n\u001B[32m    348\u001B[39m     retain_graph = create_graph\n\u001B[32m    350\u001B[39m \u001B[38;5;66;03m# The reason we repeat the same comment below is that\u001B[39;00m\n\u001B[32m    351\u001B[39m \u001B[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001B[39;00m\n\u001B[32m    352\u001B[39m \u001B[38;5;66;03m# calls in the traceback and some print out the last line\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m353\u001B[39m \u001B[43m_engine_run_backward\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    354\u001B[39m \u001B[43m    \u001B[49m\u001B[43mtensors\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    355\u001B[39m \u001B[43m    \u001B[49m\u001B[43mgrad_tensors_\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    356\u001B[39m \u001B[43m    \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    357\u001B[39m \u001B[43m    \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    358\u001B[39m \u001B[43m    \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    359\u001B[39m \u001B[43m    \u001B[49m\u001B[43mallow_unreachable\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[32m    360\u001B[39m \u001B[43m    \u001B[49m\u001B[43maccumulate_grad\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[32m    361\u001B[39m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Dokumente/Projekte/hasca-wear/venv/lib/python3.12/site-packages/torch/autograd/graph.py:824\u001B[39m, in \u001B[36m_engine_run_backward\u001B[39m\u001B[34m(t_outputs, *args, **kwargs)\u001B[39m\n\u001B[32m    822\u001B[39m     unregister_hooks = _register_logging_hooks_on_whole_graph(t_outputs)\n\u001B[32m    823\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m824\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mVariable\u001B[49m\u001B[43m.\u001B[49m\u001B[43m_execution_engine\u001B[49m\u001B[43m.\u001B[49m\u001B[43mrun_backward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001B[39;49;00m\n\u001B[32m    825\u001B[39m \u001B[43m        \u001B[49m\u001B[43mt_outputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\n\u001B[32m    826\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001B[39;00m\n\u001B[32m    827\u001B[39m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[32m    828\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m attach_logging_hooks:\n",
      "\u001B[31mKeyboardInterrupt\u001B[39m: "
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-02T22:29:26.873529Z",
     "start_time": "2025-07-02T22:29:26.864021Z"
    }
   },
   "cell_type": "code",
   "source": "original_labels",
   "id": "fbd067515a7b3c40",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[np.int64(1),\n",
       " np.int64(2),\n",
       " np.int64(3),\n",
       " np.int64(4),\n",
       " np.int64(5),\n",
       " np.int64(6),\n",
       " np.int64(7),\n",
       " np.int64(8),\n",
       " np.int64(9),\n",
       " np.int64(10),\n",
       " np.int64(11),\n",
       " np.int64(12),\n",
       " np.int64(13),\n",
       " np.int64(14),\n",
       " np.int64(15),\n",
       " np.int64(16),\n",
       " np.int64(17),\n",
       " np.int64(18)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "a7ac37b3d18d252c"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
