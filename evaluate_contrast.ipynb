{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-02T22:33:59.618165Z",
     "start_time": "2025-07-02T22:33:59.613085Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm"
   ],
   "id": "b40be22d50ed38df",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-02T22:33:59.784168Z",
     "start_time": "2025-07-02T22:33:59.773371Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class DeepConvLSTM_contrastive(nn.Module):\n",
    "    def __init__(self, num_channels, embedding_dim=128):\n",
    "        super().__init__()\n",
    "        # Backbone\n",
    "        self.conv1 = nn.Conv1d(num_channels, 64, kernel_size=5, padding=2)\n",
    "        self.conv2 = nn.Conv1d(64, 128, kernel_size=5, padding=2)\n",
    "        self.conv3 = nn.Conv1d(128, 128, kernel_size=5, padding=2)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.pool = nn.MaxPool1d(2)\n",
    "        self.lstm = nn.LSTM(128, 128, num_layers=2, batch_first=True)\n",
    "\n",
    "        # Projection Head\n",
    "        self.projection = nn.Sequential(\n",
    "            nn.Linear(128, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, embedding_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Backbone forward pass\n",
    "        x = x.permute(0, 2, 1)\n",
    "        x = self.relu(self.conv1(x)); x = self.pool(x)\n",
    "        x = self.relu(self.conv2(x)); x = self.pool(x)\n",
    "        x = self.relu(self.conv3(x)); x = self.pool(x)\n",
    "        x = x.permute(0, 2, 1)\n",
    "        out, _ = self.lstm(x)\n",
    "        features = out[:, -1, :]\n",
    "\n",
    "        # Projection head forward pass\n",
    "        projection = self.projection(features)\n",
    "\n",
    "        return features, projection"
   ],
   "id": "df374cf67da14c7d",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-02T22:33:59.922531Z",
     "start_time": "2025-07-02T22:33:59.916873Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "class LinearClassifier(nn.Module):\n",
    "    def __init__(self, input_dim, num_classes):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(input_dim, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.linear(x)\n"
   ],
   "id": "dc610bf6fc9d599a",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-02T22:35:43.800442Z",
     "start_time": "2025-07-02T22:35:43.794567Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "class DeepMLPClassifier(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim_1, hidden_dim_2, num_classes, dropout_rate=0.5):\n",
    "        super().__init__()\n",
    "        self.network = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim_1),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(hidden_dim_1, hidden_dim_2),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(hidden_dim_2, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.network(x)\n"
   ],
   "id": "c3d610f06c12eefa",
   "outputs": [],
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-07-02T22:36:08.116696Z",
     "start_time": "2025-07-02T22:35:44.411498Z"
    }
   },
   "source": [
    "# 1. Load the test data\n",
    "test_data_df = pd.read_csv(\"./data/test.csv\")\n",
    "CONFIDENCE_THRESHOLD = 0.7\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "batch_size = 64\n",
    "original_labels = [np.int64(1),\n",
    " np.int64(2),\n",
    " np.int64(3),\n",
    " np.int64(4),\n",
    " np.int64(5),\n",
    " np.int64(6),\n",
    " np.int64(7),\n",
    " np.int64(8),\n",
    " np.int64(9),\n",
    " np.int64(10),\n",
    " np.int64(11),\n",
    " np.int64(12),\n",
    " np.int64(13),\n",
    " np.int64(14),\n",
    " np.int64(15),\n",
    " np.int64(16),\n",
    " np.int64(17),\n",
    " np.int64(18)]\n",
    "# 2. Process the pre-windowed data\n",
    "# Convert string representation of lists to actual numpy arrays\n",
    "test_data_df[\"x_axis\"] = test_data_df[\"x_axis\"].apply(lambda row: np.array(eval(row), dtype=np.float32))\n",
    "test_data_df[\"y_axis\"] = test_data_df[\"y_axis\"].apply(lambda row: np.array(eval(row), dtype=np.float32))\n",
    "test_data_df[\"z_axis\"] = test_data_df[\"z_axis\"].apply(lambda row: np.array(eval(row), dtype=np.float32))\n",
    "result_df_list = []\n",
    "for i, entry in enumerate([\"right_arm\", \"left_arm\", \"left_leg\", \"right_leg\"]):\n",
    "    # Stack the axes to create a single numpy array for X_test\n",
    "    # The shape will be (num_samples, sequence_length, num_channels) -> (n, 50, 3)\n",
    "    test_df = test_data_df[test_data_df[\"sensor_location\"] == entry]\n",
    "    contrastive_model = torch.load(f\"models/DeepConvContrast/2_{i}_contrast.pt\", weights_only=False, map_location=torch.device('cpu'))\n",
    "    classifier = torch.load(f\"models/DeepConvContrast/2_{i}_classifier.pt\", weights_only=False, map_location=torch.device('cpu'))\n",
    "    X_test_unscaled = np.stack([\n",
    "        np.vstack(test_df[\"x_axis\"].values),\n",
    "        np.vstack(test_df[\"y_axis\"].values),\n",
    "        np.vstack(test_df[\"z_axis\"].values)\n",
    "    ], axis=-1)\n",
    "\n",
    "    print(f\"Shape of unscaled test data: {X_test_unscaled.shape}\")\n",
    "\n",
    "    # 3. Scale the data using the *original* scaler\n",
    "    # The scaler expects a 2D array, so we reshape, transform, and then reshape back\n",
    "    num_samples, seq_len, num_features = X_test_unscaled.shape\n",
    "    X_test_reshaped = X_test_unscaled.reshape(-1, num_features)\n",
    "    scaler = StandardScaler()\n",
    "    X_test_scaled_reshaped = scaler.fit_transform(X_test_reshaped)\n",
    "    X_test = X_test_scaled_reshaped.reshape(num_samples, seq_len, num_features)\n",
    "\n",
    "    print(f\"Shape of final test data: {X_test.shape}\")\n",
    "\n",
    "    # 4. Create DataLoader for the test set\n",
    "    X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "\n",
    "    class TestDataset(Dataset):\n",
    "        def __init__(self, data):\n",
    "            self.data = torch.tensor(data, dtype=torch.float32)\n",
    "\n",
    "        def __len__(self):\n",
    "            return len(self.data)\n",
    "\n",
    "        def __getitem__(self, idx):\n",
    "            return self.data[idx]\n",
    "\n",
    "    test_dataset = TestDataset(X_test)\n",
    "    # Make sure drop_last=False to evaluate all test samples\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, drop_last=False)\n",
    "\n",
    "    # 5. Make predictions with the trained model\n",
    "    contrastive_model.eval()\n",
    "    classifier.eval()\n",
    "    all_preds = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for Xb in tqdm(test_loader, desc=\"Making predictions\"):\n",
    "            Xb = Xb.to(device)\n",
    "\n",
    "            # Get features from the frozen backbone\n",
    "            features, _ = contrastive_model(Xb)\n",
    "            # Get predictions from the classifier\n",
    "            logits = classifier(features)\n",
    "            probabilities = torch.softmax(logits, dim=1)\n",
    "            max_probs, predicted_indices = torch.max(probabilities, dim=1)\n",
    "\n",
    "            final_predictions = []\n",
    "            for i in range(len(max_probs)):\n",
    "                if max_probs[i] < CONFIDENCE_THRESHOLD:\n",
    "                    # If confidence is low, predict the 'null' class (original label 0)\n",
    "                    final_predictions.append(0)\n",
    "                else:\n",
    "                    # Otherwise, use the model's prediction and map it back to its original label\n",
    "                    remapped_idx = predicted_indices[i].item()\n",
    "                    original_label = original_labels[remapped_idx]\n",
    "                    final_predictions.append(original_label)\n",
    "            all_preds.extend(final_predictions)\n",
    "\n",
    "    # 6. Generate submission file\n",
    "    result_df = pd.DataFrame({\n",
    "        'id': test_df[\"id\"].values,\n",
    "        'label': all_preds\n",
    "    })\n",
    "    result_df_list.append(result_df)\n",
    "\n",
    "result_df = pd.concat(result_df_list, ignore_index=True)\n",
    "result_df.to_csv(\"submission.csv\", index=False)\n",
    "\n",
    "print(\"\\nSubmission file 'submission.csv' created successfully.\")\n",
    "print(result_df.head())\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of unscaled test data: (12234, 50, 3)\n",
      "Shape of final test data: (12234, 50, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Making predictions: 100%|██████████| 192/192 [00:01<00:00, 161.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of unscaled test data: (12234, 50, 3)\n",
      "Shape of final test data: (12234, 50, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Making predictions: 100%|██████████| 192/192 [00:01<00:00, 165.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of unscaled test data: (12234, 50, 3)\n",
      "Shape of final test data: (12234, 50, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Making predictions: 100%|██████████| 192/192 [00:01<00:00, 155.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of unscaled test data: (12234, 50, 3)\n",
      "Shape of final test data: (12234, 50, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Making predictions: 100%|██████████| 192/192 [00:01<00:00, 159.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Submission file 'submission.csv' created successfully.\n",
      "   id  label\n",
      "0   0      0\n",
      "1   1      6\n",
      "2   2      0\n",
      "3   3      0\n",
      "4   4     12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "17b1e5a6cb10d571"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
